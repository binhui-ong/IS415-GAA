[
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2: R for Geospatial Analytics",
    "section": "",
    "text": "2.1 Getting Started\nTo begin with, we will use p_load() from pacman package to load the following packages:\n\narrow,\nlubridate,\ntidyverse,\ntmap, and\nsf.\n\n\n\nCode\npacman::p_load(arrow, lubridate, tidyverse, tmap, sf)\n\n\n\n\n2.2 Importing Grab-Posisi Dataset\nImport the parquet file into R and name the data frame as df:\n\n\nCode\ndf &lt;- read_parquet(\"data/GrabPosisi/part-00008-8bbff892-97d2-4011-9961-703e38972569.c000.snappy.parquet\")\n\n\nTo convert pingtimestamp field from integer to datetime data format:\n\n\nCode\ndf$pingtimestamp &lt;- as_datetime(df$pingtimestamp)\n\n\nSave the newly reformatted df data frame as rds for future use:\n\n\nCode\nwrite_rds(df, \"data/rds/part0.rds\")\n\n\nExtracting trip starting locations\n\n\nCode\norigin_df &lt;- df %&gt;%\n  group_by(trj_id) %&gt;%\n  arrange(pingtimestamp) %&gt;%\n  filter(row_number() == 1) %&gt;%\n  mutate(weekday = wday(pingtimestamp,\n                         label = TRUE,\n                         abbr = TRUE),\n         start_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\nExtracting trip destination locations\n\n\nCode\ndestination_df &lt;- df %&gt;%\n  group_by(trj_id) %&gt;%\n  arrange(desc(pingtimestamp)) %&gt;%\n  filter(row_number() == 1) %&gt;%\n  mutate(weekday = wday(pingtimestamp,\n                         label = TRUE,\n                         abbr = TRUE),\n         end_hr = factor(hour(pingtimestamp)),\n         day = factor(mday(pingtimestamp)))\n\n\nSave the newly created origin_df and destination_df dataframes as rds files for future use:\n\n\nCode\nwrite_rds(origin_df,\"data/rds/origin_df.rds\")\nwrite_rds(destination_df, \"data/rds/destination_df.rds\")\n\n\nTo import the objects the next time I reopen the R project,\n\n\nCode\norigin_df &lt;- read_rds(\"data/rds/origin_df.rds\")\ndestination_df &lt;- read_rds(\"data/rds/destination_df.rds\")"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Bin Hui",
    "section": "",
    "text": "Hi there!\nI am Ong Bin Hui, a third-year student at the Singapore Management University (SMU), majoring in Finance with a second major in Data Science and Analytics.\nApart from my love for music and the exciting world of Finance and Investments, I am very passionate in understanding and harnessing the power of Data Science and Analytics!\nWhy so?\nI believe Data Science and Analytics has a wonderful ability and potential to bring tremendous value to societies and the world in an uncountable number of aspects like healthcare, housing and many more… all of which can uplift lives!\nWith that, I am actively pursuing knowledge and experience in this area, in hopes I can effectively utilize them to contribute to the greater good. Geospatial Analytics, which is the course I am journaling about on this website, is an example of a skill I believe can help me in moving closer towards my goals.\nI hope you’ll enjoy looking through my course work and potentially be inspired about this skill as well! Should you like to chat with me, you can drop me an email at @binhui.ong.2021@business.smu.edu.sg!\nHave a great day ahead! :D\np.s.: Here’s a feel-good song to make your day better: Get a Guitar by RIIZE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this exercise, we will delve into the processes of importing, transforming and analyzing geospatial and apatial data in R with the use of sf and tidyverse packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#installing-and-loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#installing-and-loading-r-packages",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Installing and Loading R Packages",
    "text": "Installing and Loading R Packages\nNext, I will install and load tidyverse and sf packages using p_load() from the pacman package. The pacman package is useful to load multiple packages at once!\n\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-geospatial-data-shapefile-format",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-geospatial-data-shapefile-format",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Importing geospatial data: shapefile format",
    "text": "Importing geospatial data: shapefile format\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/binhui-ong/IS415-GAA/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\ncyclingpath &lt;- st_read(dsn = \"data/geospatial\",\n                       layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `/Users/binhui-ong/IS415-GAA/Hands-on_Ex/Hands-on_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-geospatial-data-kml-format",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-geospatial-data-kml-format",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Importing geospatial data: kml format",
    "text": "Importing geospatial data: kml format\n\npreschool &lt;- st_read(dsn = \"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/binhui-ong/IS415-GAA/Hands-on_Ex/Hands-on_Ex01/data/geospatial/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-st_geometry",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-st_geometry",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.5.1 Working with st_geometry()",
    "text": "1.5.1 Working with st_geometry()\nBesides mpsz$geom and mpsz, we can retrieve the geometry list-column in an sf data.frame using st_geometry().\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nThis would display only basic information of the feature class such as type of geometry, geographic extent of the features, and coordinate system of the data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-glimpse",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-glimpse",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.5.2 Working with glimpse()",
    "text": "1.5.2 Working with glimpse()\nWe can also learn more about the associated attribute information in the data frame using glimpse(0) of dplyr.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-head",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-head",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.5.3. Working with head()",
    "text": "1.5.3. Working with head()\nTo find out complete information of a feature object, we can use head() of Base R.\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code-to-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code-to-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.7.1 Assigning EPSG code to a simple feature data frame",
    "text": "1.7.1 Assigning EPSG code to a simple feature data frame\nWe use st_crs() from the sf package to retrieve the coordinate reference system for an object.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nWe see that the EPSG assigned to mpsz is 9001. However, the EPSG for svy21 is actually 3414.\nHence, we have to assign a new EPSG to mpsz. We define the updated mpsz as mpsz3414 using st_set_crs() from the sf package.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nLet’s check that the EPSG is correct now.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.7.2 Transforming the projection of preschool from wgs84 to svy21",
    "text": "1.7.2 Transforming the projection of preschool from wgs84 to svy21\nIn geospatial analytics, we often transform the original data from geographic coordinate system to projected coordinate system. This facilitates analysis involving distance and/or area measurements.\nAs seen earlier in 1.5.1, the preschool simple feature data frame shows that it is in wgs84 coordinate system.\nTo perform the projection transformation,\n\npreschool3414 &lt;- st_transform(preschool, crs =3414)\n\nThe new preschool3414 data frame is as follows:\n\n\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n     Name\n1   kml_1\n2   kml_2\n3   kml_3\n4   kml_4\n5   kml_5\n6   kml_6\n7   kml_7\n8   kml_8\n9   kml_9\n10 kml_10\n                                                                                                                                                                                                                                                                                                                                                                                                                  Description\n1                             &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;CHILDREN'S COVE PRESCHOOL PTE.LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;PT9390&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;498CC9FE48CC94D4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n2                                      &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;CHILDREN'S COVE PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;PT8675&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;22877550804213FD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n3                         &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;CHILDREN'S VINEYARD PRESCHOOL PTE. LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;PT9308&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;B2FE90E44AD494E3&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n4                   &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;CHILDTIME CARE & DEVELOPMENT CENTRE PTE.LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;PT9122&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;1384CDC0D14B76A1&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n5                                                 &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;CHILTERN HOUSE&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;PT2070&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;FB24EAA6E73B2723&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n6                                      &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;CHILTERN HOUSE EAST COAST&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;PT6550&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;B53C79DF64135499&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n7                                     &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;CHILTERN HOUSE MOUNTBATTEN&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;PT8637&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;B53C79DFBF7AD96F&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n8                                       &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;CHILTERN HOUSE TURF CLUB&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;PT5400&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;8F2BC6E9BF962BC8&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n9                              &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;CHINESE CHRISTIAN MISSION LIMITED&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;RC0740&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;CA317E72A442CEB6&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n10 &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;CHOW & CHOWS CHILDCARE & EARLY LEARNING CENTRE (CCK 542) LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;RC1775&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;2072C1C4F5E69A9C&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n                        geometry\n1  POINT Z (25089.46 31299.16 0)\n2  POINT Z (27189.07 32792.54 0)\n3  POINT Z (28844.56 36773.76 0)\n4  POINT Z (24821.92 46303.16 0)\n5  POINT Z (28637.82 35038.49 0)\n6  POINT Z (33248.74 32260.59 0)\n7  POINT Z (33248.74 32260.59 0)\n8   POINT Z (23591.47 35202.8 0)\n9  POINT Z (18338.28 36619.18 0)\n10 POINT Z (18148.23 41723.46 0)\n\n\nYay! The preschool location data is in svy projected coordinate system now.\nAdditionally, looking at the Bounding box, the values are larger than the 0-360 decimal degree commonly used by most of the geographic coordinate systems."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-aspatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.8.1 Importing Aspatial Data",
    "text": "1.8.1 Importing Aspatial Data\nAs the data is in csv format, we will use read_csv() of readr package to import listing.csv. The output R object is called listings and it is a tibble data frame.\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nTo check if the data file has been imported correctly, we can also use list() of Base R to check the tibble data frame.\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,457 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,447 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nThe output reveals that listing tibble data frame consists of 3,457 rows and 18 columns.\nTwo useful fields we are going to use in the next phase are latitude and longitude. As they are in the decimal degree format, we could assume that the data is in wgs84 Geographic Coordinate System."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.8.2 Creating a simple feature data frame from an aspatial data frame",
    "text": "1.8.2 Creating a simple feature data frame from an aspatial data frame\nThe following code chunk converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\nlistings_sf &lt;- st_as_sf(listings, \n                        coords = c(\"longitude\", \"latitude\"),\n                        crs=4326) |&gt;\n  st_transform(crs=3414)\n\n\nglimpse(listings_sf)\n\nRows: 3,457\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 150, 80, 80, 64, 78, 220, 85, 75, 69, 7…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.13, 0.16, 0.30, 0.15, 0.11, 0.09, 0.9…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 51, 51, 5, 7, 51, 51, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 55, 91, 91, 183, 183, 54, 365, 183, 183…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 2, 0, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.9.1 Buffering",
    "text": "1.9.1 Buffering\nCase: The authority is planning to upgrade the existing cycling path. To do so, they need to acquire 5 metres of reserved land on both sides of the current cycling path. You are tassked to determine the extent of land to be acquired and their total area.\nSolution:\nStep 1: Compute the 5-meter buffers around cycling paths with st_buffer() of sf package.\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, dist = 5, nQuadSegs = 30)\n\nStep 2: Calculate the area of the buffers with st_area() of sf package.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nStep 3: Derive the total land involved with sum() of Base R.\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]\n\n\nTADAH! We’re done!"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.9.2 Point-in-polygon count",
    "text": "1.9.2 Point-in-polygon count\nCase: A pre-school service group wants to find out the number of pre-schools in each Planning Subzome.\nSolution:\nStep 1:\n\nmpsz3414$'PreSch Count' &lt;- lengths(st_intersects (mpsz3414, preschool3414))\n\nStep 2:\n\nsummary(mpsz3414$'PreSch Count')\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nStep 3:\n\ntop_n(mpsz3414, 1, 'PreSch Count')\n\nSimple feature collection with 323 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...            0\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...            6\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...            0\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...            5\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...            3\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...           13\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...            5\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...            1\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...           11\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...            1\n\n\nAdditional Question: Calculate the density of pre-school by planning subzone.\nSolution:\nStep 1: Derive the area of each planning subzone with st_area() from sf package.\n\nmpsz3414$Area &lt;- mpsz3414 |&gt;\n                st_area()\n\nStep 2: Compute the density with mutate() of dplyr package.\n\nmpsz3414 &lt;- mpsz3414 |&gt;\n        mutate(`PreSch Density` = (`PreSch Count`/Area * 1000000))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution of a set of points on a surface. The point can be location of:\n\nevents such as crime, traffic accident and disease onset,\nor business services (coffee and fast food outlets) or facilities such as childcare and eldercare.\n\nIn this exercise, we will use appropriate functions of spatstat to discover the spatial point processes of childcare centres in Singapore.\nThe specific questions we would like to answer are as follows:\n\nAre childcare centres in Singapore randomly distributed throughout the country?\nIf the answer is no, then the next logical question is: Where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-the-spatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-the-spatial-data",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.4.1. Importing the spatial data",
    "text": "4.4.1. Importing the spatial data\nIn this section, we will use st_read() from the sf package to import the three geospatial data sets into R.\n\n#|eval: FALSE\nchildcare_sf &lt;- st_read(dsn = \"data/ChildCareServices.geojson\") %&gt;%\n  st_transform(crs=3414)\n\n\n#|eval: FALSE\nsg_sf &lt;- st_read(dsn=\"data\", layer = \"MP14_SUBZONE_WEB_PL\") %&gt;% st_union()\n\n\n#|eval: FALSE\nmpsz_sf &lt;- st_read(dsn=\"data\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nBefore we use the data sets for analysis, we should check if they have all been correctly projected into the SVY21 coordinate system,\n\nst_crs(childcare_sf)\n\n\nst_crs(sg_sf)\n\n\nst_crs(mpsz_sf)\n\nSince the sg_sf and mpsz_sf data sets do not have the correct EPSG code, we can change them using st_set_crs().\n\nsg_sf&lt;- st_set_crs(sg_sf, 3414)\n\n\nmpsz_sf &lt;- st_set_crs(mpsz_sf, 3414)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#mapping-the-geospatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#mapping-the-geospatial-data-sets",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.4.2 Mapping the geospatial data sets",
    "text": "4.4.2 Mapping the geospatial data sets\nAfter checking the referencing system of each geospatial data frame, it is also useful for us to plot a map to show their spatial patterns.\n\ntm_shape(sg_sf) + tm_polygons() + \ntm_shape(mpsz_sf) + tm_polygons() + \ntm_shape(childcare_sf) + tm_dots()\n\nNotice that all the geospatial layers are within the same map extend. This shows that their referencing system and coordinate values are referred to similar spatial context. This is very important in any geospatial analysis.\nWe can create a pin map by using the following code chunk:\n\ntmap_mode('view') \ntm_shape(childcare_sf) + \n  tm_dots()\n\nIn the interactive mode, tmap is using leaflet for R API. This interactive pin map allows us to navigate and zoom around the map freely.\nAdditionally, we can query the information of each simple feature (i.e. the point) by clicking it.\nLastly, we can change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\nThereafter, we switch back to plot mode as the interactive mode will consume a connection.\n\ntmap_mode('plot')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-sf-data-frames-to-sps-spatial-class",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-sf-data-frames-to-sps-spatial-class",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.5.1 Converting sf data frames to sp’s Spatial* class",
    "text": "4.5.1 Converting sf data frames to sp’s Spatial* class\nTo convert geospatial data from sf data frame to sp’s Spatial* class, we use as_Spatial() from sf package.\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\nTo look into the information of the three new Spatial* classes,\n\nchildcare\n\n\nmpsz\n\n\nsg"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-spatial-class-into-generic-sp-format",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-spatial-class-into-generic-sp-format",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.5.2. Converting the Spatial* class into generic sp format",
    "text": "4.5.2. Converting the Spatial* class into generic sp format\nspatstat requires the analytical data in to be in ppp object form. As there is no direct way to convert a Spatial* classes into ppp object, we would need to convert the Spatial* classes into Spatial object first.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nThen, we should look into the sp objects properties:\n\nchildcare_sp\n\n\nsg_sp\n\nWith the conversion from Spatial* class into generic sp format, the spatial data frames are converted into spatial objects."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.5.3 Converting the generic sp format into spatstat’s ppp format",
    "text": "4.5.3 Converting the generic sp format into spatstat’s ppp format\nNext, we will use as.ppp() from spatstat package to convert the spatial data into spatstat’s ppp object format:\n\nchildcare_ppp &lt;- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nHere, we can plot childcare_ppp to examine the difference.\n\nplot(childcare_ppp)\n\nTo have a quick understanding of the summary statistics of the newly created ppp object, we can use the following code:\n\nsummary(childcare_ppp)\n\nFrom the above summary, we notice the warning message about duplicates. In spatial point patterns analysis, the presence of duplicates is a significant issue The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#handling-duplicated-points",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#handling-duplicated-points",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.5.4. Handling duplicated points",
    "text": "4.5.4. Handling duplicated points\nWe can check for duplication in a ppp object by using the following code chunk:\n\nany(duplicated(childcare_ppp))\n\nTo find out the number of coincident points, we use the multiplicity() function from spatstat package:\n\nmultiplicity(childcare_ppp)\n\nTo find out how many locations have more than one point event, we can use the code:\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\nThe output shows that there are 338 duplicated point events.\nTo view the location of these duplicate point events, we will plot childcare data with the following code chunk:\n\ntmap_mode('view')\ntm_shape(childcare) + \n  tm_dots(alpha=0.4, \n          size = 0.05)\n\nFrom the graph above, we can spot the duplicate point events as the duplicate points overlap, resulting in darker points in the map.\nAfter plotting the graph, we adjust our tmap_mode back to static setting:\n\ntmap_mode('plot')\n\nTo overcome the issue of duplicate points, we can use any of the following 3 solutions:\n\nDelete the duplicates (however, this would lead to the loss of some useful point events)\nJittering: To add a small pertubation to the duplicate points, so that they do not occupy the exact same space\nMake each point “unique”, and attach the duplicates of the points to the patterns as marks, as attributes of the points. Then, we would need analytical techniques that take into account these marks.\n\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE,\n                             nsim = 1,\n                             drop = TRUE)\n\n\nany(duplicated(childcare_ppp_jit))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-owin-object",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.5.5 Creating owin object",
    "text": "4.5.5 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis within a geographical area like Singapore’s boundary. In spatstat, an object called owin is designed to represent this polygonal region.\nThe code chunk below is used to convert sg sf object into owin object of spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nThe output object can be displayed by using the plot() function\n\nplot(sg_owin)\n\nand summary() function of Base R.\n\nsummary(sg_owin)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#combining-point-events-object-and-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#combining-point-events-object-and-owin-object",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.5.6 Combining point events object and owin object",
    "text": "4.5.6 Combining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp &lt;- childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nsummary(childcareSG_ppp)\n\nTo plot the newly derived childcareSG_ppp map,\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#kernel-density-estimation-kde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#kernel-density-estimation-kde",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.6.1 Kernel Density Estimation (KDE)",
    "text": "4.6.1 Kernel Density Estimation (KDE)\nIn this section, we will learn how to compute the kernel density estimation (KDE) of childcare services in Singapore.\n\n4.6.1.1 Computing KDE using automatic bandwidth selection method\nThe code chunk below computes a Kernel Density by using the following configurations of density() of spatstat:\n\nAutomatic bandwidth selection method: bw.diggle()\n\nOther recommended methods: bw.CvL(), bw.scott() or bw.ppl()\n\nSmoothing kernel: “gaussian”\n\nOther smoothing methods: “epanechnikov”, “quartic” or “disc”\n\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma = bw.diggle,\n                              edge = TRUE,\n                              kernel = \"gaussian\")\n\nThe plot() function of Base R is then used to display the kernel density derived.\n\nplot(kde_childcareSG_bw)\n\nThe density values of the output range from 0 to 0.00003 which is way too small to comprehend. This is because the default unit of measurement of svy21 is in meter. As a result, the density values computed is in “number of points per square meter”.\nBefore we move on to next section, it is good to know that you can retrieve the bandwidth used to compute the kde layer by using the code chunk below.\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n\n\n4.6.1.2 Rescaling KDE values\nIn the following code chunk, rescale() is used to convert the unit of measurement from meter to kilometer.\n\nchildcareSG_ppp.km &lt;- rescale (childcareSG_ppp, 1000, \"km\")\n\nNow, we can re-run density() using the rescaled data set and plot the output kde map.\n\nkde_childcareSG.bw.km &lt;- density(childcareSG_ppp.km,\n                                 sigma = bw.diggle,\n                                 edge = TRUE,\n                                 kernel = \"gaussian\")\nplot(kde_childcareSG.bw.km)\n\nNow, we can see that the output image looks identical to the earlier version, but with more intepretable data values in the legend."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#working-with-different-automatic-bandwidth-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#working-with-different-automatic-bandwidth-methods",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.6.2 Working with different automatic bandwidth methods",
    "text": "4.6.2 Working with different automatic bandwidth methods\nBeside bw.diggle(), I mentioned that there are three other spatstat functions that can be used to determine the bandwidth, which are: bw.CvL(), bw.scott(), and bw.ppl().\nLet us take a look at the bandwidth return by these automatic bandwidth calculation methods by using the code chunk below.\n\nbw.CvL(childcareSG_ppp.km)\n\n\nbw.scott(childcareSG_ppp.km)\n\n\nbw.ppl(childcareSG_ppp.km)\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because based on their experience, it tends to produce more appropriate values when the pattern consists predominantly of tight clusters.\nHowever, they also insist that if the purpose of a study is to detect a single tight cluster in the midst of random noise, the bw.diggle() method seems to work best.\nThe following code chunk is used to compare the difference in output using bw.diggle and bw.ppl() methods.\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km,\n                               sigma = bw.ppl,\n                               edge = TRUE,\n                               kernel = \"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw.km, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#working-with-different-kernel-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#working-with-different-kernel-methods",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.6.3 Working with different kernel methods",
    "text": "4.6.3 Working with different kernel methods\nBy default, the kernel method used in density.ppp() is Gaussian. However, there are three other options, namely: Epanechnikov, Quartic and Dics.\nThe code chunk below will be used to compute 3 more kernel density estimations by using these 3 kernel functions.\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km,\n             sigma = bw.ppl,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"gaussian\")\nplot(density(childcareSG_ppp.km,\n             sigma = bw.ppl,\n             edge = TRUE,\n             kernel = \"epanechnikov\"),\n     main = \"Epanechnikov\")\nplot(density(childcareSG_ppp.km,\n             sigma = bw.ppl,\n             edge = TRUE,\n             kernel = \"quartic\"),\n     main = \"quartic\")\nplot(density(childcareSG_ppp.km,\n             sigma = bw.ppl,\n             edge = TRUE,\n             kernel = \"disc\"),\n     main = \"disc\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-kde-by-using-fixed-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-kde-by-using-fixed-bandwidth",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.7.1 Computing KDE by using fixed bandwidth",
    "text": "4.7.1 Computing KDE by using fixed bandwidth\nNext, you will compute a KDE layer by defining a bandwidth of 600 meter.\nNotice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km,\n                               sigma = 0.6, \n                               edge = TRUE,\n                               kernel = \"gaussian\")\nplot (kde_childcareSG_600)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-kde-by-using-adaptive-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#computing-kde-by-using-adaptive-bandwidth",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.7.2 Computing KDE by using adaptive bandwidth",
    "text": "4.7.2 Computing KDE by using adaptive bandwidth\nFixed bandwidth method is very sensitive to highly skewed distribution of spatial point patterns over geographical units (for example, urban versus rural). One way to overcome this problem is by using adaptive bandwidth instead.\nIn this section, we will learn how to derive adaptive kernel density estimation by using density.adaptive() of spatstat.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km,\n                                             method = \"kernel\")\nplot(kde_childcareSG_adaptive)\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below:\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw.km, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-kde-output-into-grid-object",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#converting-kde-output-into-grid-object",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.7.3 Converting KDE output into grid object",
    "text": "4.7.3 Converting KDE output into grid object\nThe result is the same, but we convert it so that it is suitable for mapping purposes.\n\ngridded_kde_childcareSG_bw &lt;- as.SpatialGridDataFrame.im(kde_childcareSG.bw.km)\nspplot(gridded_kde_childcareSG_bw)\n\n\n4.7.3.1 Converting gridded output into raster\nNext, we will convert the gridded kernel density objects into RasterLayer object by using raster() of raster package.\n\nkde_childcareSG_bw_raster &lt;- raster(gridded_kde_childcareSG_bw)\n\nLet us take a look at the properties of kde_childcareSG_bw_raster RasterLayer object.\n\nkde_childcareSG_bw_raster\n\nNotice that the crs property is NA.\n\n\n4.7.3.2 Assigning projection systems\nSince the crs property of kde_childcareSG_bw_raster RasterLayer object is NA, we will include CRS information for it using the code below.\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nNow, we see that the crs property is complete."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#visualising-the-output-in-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#visualising-the-output-in-tmap",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.7.4 Visualising the output in tmap",
    "text": "4.7.4 Visualising the output in tmap\nFinally, we will display the raster in cartographic quality map using tmap package.\n\ntmap_mode(\"plot\")\ntm_shape (kde_childcareSG_bw_raster) + \n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), \n            frame = FALSE)\n\nNotice that the raster values are encoded explicitly onto the raster pixel using the values in the “v” field."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#comparing-spatial-point-patterns-using-kde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#comparing-spatial-point-patterns-using-kde",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.7.5 Comparing Spatial Point Patterns using KDE",
    "text": "4.7.5 Comparing Spatial Point Patterns using KDE\nIn this section, we will learn to compare KDE of childcare at Punggol, Tampines, Choa Chu Kang and Jurong West planning areas.\n\n4.7.5.1 Extracting study area\nThe code chunk below will be used to extract the target planning areas.\n\npg &lt;- mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\", ] \ntm &lt;- mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\", ]\nck &lt;- mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\", ] \njw &lt;- mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\", ] \n\nPlotting target planning areas:\n\npar(mfrow = c(2,2))\nplot(pg, main = \"Punggol\")\nplot(tm, main = \"Tampines\")\nplot(ck, main= \"Choa Chu Kang\")\nplot(jw, main = \"Jurong West\")\n\n\n\n4.7.5.2 Converting the spatial point data frame into generic sp format\nNext, we will convert these SpatialPolygonsDataFrame layers into generic spatialpolygons layers.\n\npg_sp &lt;- as(pg,\"SpatialPolygons\")\ntm_sp &lt;-  as(tm,\"SpatialPolygons\")\nck_sp &lt;- as(ck, \"SpatialPolygons\")\njw_sp &lt;-  as(jw,\"SpatialPolygons\")\n\n\n\n4.7.5.3 Creating owin object\nNow, we will convert these SpatialPolygons objects into owin objects that is required by spatstat.\n\npg_owin &lt;- as(pg_sp, \"owin\")\ntm_owin &lt;- as(tm_sp, \"owin\")\nck_owin &lt;- as(ck_sp, \"owin\")\njw_owin &lt;- as(jw_sp, \"owin\")\n\n\n\n4.7.5.4 Combining childcare points and the study area\nBy using the code chunk below, we can extract the childcare centres that are within specific regions to conduct out analysis later on.\n\nchildcare_pg_ppp &lt;- childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp &lt;- childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp &lt;- childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp &lt;- childcare_ppp_jit[jw_owin]\n\nNext, we use rescale() to transform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km &lt;- rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km &lt;- rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km &lt;- rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km &lt;- rescale(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the location of the childcare centres.\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main = \"Punggol\")\nplot(childcare_tm_ppp.km, main = \"Tampines\")\nplot(childcare_ck_ppp.km, main = \"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main = \"Jurong West\")\n\n\n\n4.7.5.5 Computing KDE\nThe code chunk below will then be used to compute the KDE of these four planning areas. bw.diggle method is used to derive the bandwidth of each.\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km,\n             sigma = bw.diggle,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Punggol\")\nplot(density(childcare_tm_ppp.km,\n             sigma = bw.diggle,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Tampines\")\nplot(density(childcare_ck_ppp.km,\n             sigma = bw.diggle,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km,\n             sigma = bw.diggle,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Jurong West\")\n\n\n\n4.7.5.6 Computing fixed bandwidth KDE\nFor comparison purposes, we will use 250m as the bandwidth.\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km,\n             sigma = 0.25,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Punggol\")\nplot(density(childcare_tm_ppp.km,\n             sigma = 0.25,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Tampines\")\nplot(density(childcare_ck_ppp.km,\n             sigma = 0.25,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km,\n             sigma = 0.25,\n             edge = TRUE,\n             kernel = \"gaussian\"),\n     main = \"Jurong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#testing-spatial-point-patterns-using-clark-and-evans-test",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#testing-spatial-point-patterns-using-clark-and-evans-test",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.8.1 Testing spatial point patterns using Clark and Evans Test",
    "text": "4.8.1 Testing spatial point patterns using Clark and Evans Test\n\nclarkevans.test(childcare_ppp,\n                correction = \"none\",\n                clipregion = \"sg_owin\",\n                alternative = c(\"clustered\"),\n                nsim = 99)\n\nSince the p-value &lt; 0.05, we have sufficient evidence at 95% confidence level that the childcare services in Singapore are not randomly distributed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#clark-and-evans-test-choa-chu-kang-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#clark-and-evans-test-choa-chu-kang-planning-area",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.8.2 Clark and Evans Test: Choa Chu Kang Planning Area",
    "text": "4.8.2 Clark and Evans Test: Choa Chu Kang Planning Area\nIn the code chunk below, clarkevans.test() of spatstat is used to performs Clark-Evans test of aggregation for childcare centre in Choa Chu Kang planning area.\n\nclarkevans.test(childcare_ck_ppp,\n                correction = \"none\",\n                clipregion = NULL,\n                alternative = c(\"two.sided\"),\n                nsim = 999)\n\nSince the p-value &gt; 0.05, we do not have sufficient evidence at 95% confidence level that the childcare services in Choa Chu Kang are not randomly distributed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#clark-and-evans-test-tampines-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#clark-and-evans-test-tampines-planning-area",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.8.3 Clark and Evans Test: Tampines Planning Area",
    "text": "4.8.3 Clark and Evans Test: Tampines Planning Area\n\nclarkevans.test(childcare_tm_ppp,\n                correction = \"none\",\n                clipregion = NULL,\n                alternative = c(\"two.sided\"),\n                nsim = 999)\n\nSince p-value &lt; 0.05, we have sufficient evidence at 95% confidence level that the childcare services in Tampines are not randomly distributed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analyzing-spatial-point-process-using-g-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analyzing-spatial-point-process-using-g-function",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.8.1 Analyzing Spatial Point Process using G-function",
    "text": "4.8.1 Analyzing Spatial Point Process using G-function\nThe G function measures the distribution of the distances from an arbitrary event to its nearest event.\nIn this section, we will learn how to compute G-function estimation by using Gest() of spatstat package. We will also learn how to perform Monta Carlo simulation test of Complete Spatial Randomness (CSR) using envelope() of spatstat package.\n\n4.8.1.1 Choa Chu Kang Planning Area\n\n4.8.1.1.1 Computing G-function estimation\nThe code chunk below is used to compute G-function using Gest() of spatstat package.\n\nG_CK &lt;- Gest(childcare_ck_ppp, \n             correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n4.8.1.1.2 Performing Complete Spatial Randomness (CSR) test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted.\nThe hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function\n\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, \n                     Gest, \n                     nsim = 999)\n\n\nplot(G_CK.csr)\n\nFrom the above plot, we can see that the estimated G function lies within the envelope. Hence, it is not statistically significant and we do not have sufficient evidence that the childcare services in Choa Chu Kang are not randomly distributed.\n\n\n\n4.8.1.2 Tampines Planning Area\n\n4.8.1.2.1 Computing G-function estimation\n\nG_TM &lt;- Gest(childcare_tm_ppp, \n             correction = \"best\")\nplot(G_TM)\n\n\n\n4.8.1.2.2 Performing Complete Spatial Randomness (CSR) test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted.\nThe hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function\n\n\nG_TM.csr &lt;- envelope(childcare_tm_ppp, Gest,\n                     correction = \"all\",\n                     nsim = 999)\n\n\nplot(G_TM.csr)\n\nFrom the above plot, we can see that the some parts of the estimated G function lies outside the envelope. Hence, it is statistically significant and we have sufficient evidence that the childcare services in Tampines are not randomly distributed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analyzing-spatial-point-process-using-f-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analyzing-spatial-point-process-using-f-function",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.8.2 Analyzing Spatial Point Process using F-function",
    "text": "4.8.2 Analyzing Spatial Point Process using F-function\nThe F function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape. In this section, we will learn how to compute F-function estimation by using Fest() of spatstat package. We will also learn how to perform Monta Carlo simulation test using envelope() of spatstat package.\n\n4.8.2.1 Choa Chu Kang Planning Area\n\n4.8.2.1.1 Computing F-function estimation\n\nF_CK &lt;- Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n4.8.2.1.2 Performing Complete Spatial Randomness (CSR) test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted.\nThe hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-function\n\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\n\nplot(F_CK.csr)\n\nFrom the above plot, we can see that the estimated F function lies within the envelope. Hence, it is not statistically significant and we do not have sufficient evidence that the childcare services in Choa Chu Kang are not randomly distributed.\n\n\n\n4.8.2.2 Tampines Planning Area\n\n4.8.2.2.1 Computing F-function estimation\n\nF_TM &lt;- Fest(childcare_tm_ppp, \n                 correction = \"best\")\nplot(F_TM)\n\n\n\n4.8.2.2.2 Performing Complete Spatial Randomness (CSR) test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted.\nThe hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-function\n\n\nF_TM.csr &lt;- envelope(childcare_tm_ppp, Fest, nsim = 999)\n\n\nplot(F_TM.csr)\n\nFrom the above plot, we can see that the some parts of the estimated F function lies outside the envelope. Hence, it is statistically significant and we have sufficient evidence that the childcare services in Tampines are not randomly distributed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analying-spatial-point-process-using-k-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analying-spatial-point-process-using-k-function",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.8.3 Analying Spatial Point Process using K-function",
    "text": "4.8.3 Analying Spatial Point Process using K-function\nK-function measures the number of events found up to a given distance of any particular event.\nIn this section, we will learn how to compute K-function estimates by using Kest() of spatstat package. We will also learn how to perform Monta Carlo simulation test using envelope() of spatstat package.\n\n4.8.3.1 Choa Chu Kang Planning Area\n\n4.8.3.1.1 Computing K-function estimate\n\nK_CK &lt;- Kest(childcare_ck_ppp, \n             correction = \"Ripley\")\nplot(K_CK, .-r~r, ylab = \"K(d) - r\", xlab = \"d(m)\")\n\n\n\n4.8.3.1.2 Performing Complete Spatial Randomness (CSR) test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted.\nThe hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nThe code chunk below is used to perform the hypothesis testing.\n\nK_CK.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank =1, glocal = TRUE)\n\n\nplot(K_CK.csr, .-r~r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n4.8.3.2 Tampines Planning Area\n\n4.8.3.2.1 Computing K-function estimates\n\nK_TM &lt;- Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_TM, . -r~r,\n     ylab = \"K(d) -r\",\n     xlab = \"d(m)\",\n     xlim = c(0,1000))\n\n\n\n4.8.3.2.2 Performing Complete Spatial Randomness (CSR) test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted.\nThe hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nThe code chunk below is used to perform the hypothesis testing.\n\nK_TM.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal = TRUE)\n\n\nplot(K_TM.csr, .-r~r, xlab= \"d\", ylab = \"K(d)-r\", xlim = c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analyzing-spatial-point-process-using-l-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analyzing-spatial-point-process-using-l-function",
    "title": "Hands-on Exercise 3: 1st Order Spatial Point Pattern Analysis Methods",
    "section": "4.8.4 Analyzing Spatial Point Process using L-function",
    "text": "4.8.4 Analyzing Spatial Point Process using L-function\nIn this section, we will learn how to compute L-function estimation by using Lest() of spatstat package. We will also learn how to perform Monta Carlo simulation test using envelope() of spatstat package.\n\n4.8.4.1 Choa Chu Kang Planning Area\n\n4.8.4.1.1 Computing L-function estimation\n\nL_CK &lt;- Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_CK, .-r~r, \n     ylab=\"L(d)-r\", xlab = \"d(m)\")\n\n\n\n4.8.4.1.2 Performing Complete Spatial Randomness (CSR) test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted.\nThe hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\n\nThe code chunk below is used to perform the hypothesis testing.\n\nL_CK.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank =1, glocal = TRUE)\n\n\nplot(L_CK.csr, .-r~r, \n     xlab = \"d\", ylab = \"L(d)-r\")\n\n\n\n\n4.8.4.2 Tampines Planning Area\n\n4.8.4.2.1 Computing L-function estimate\n\nL_TM &lt;- Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_TM, .-r~r, \n     ylab = \"L(d)-r\", xlab = \"d(m)\",\n     xlim = c(0,1000))\n\n\n\n4.8.4.2.2 Performing Complete Spatial Randomness (CSR) test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted.\nThe hypothesis and test are as follows:\n\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\n\nThe code chunk below is used to perform the hypothesis testing.\n\nL_TM.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal = TRUE)\n\n\nplot(L_TM.csr, .-r~r, \n     xlab = \"d\", ylab = \"L(d)-r\", xlim = c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualization with R",
    "section": "",
    "text": "In this exercise, I will be demonstrating the use of R packages to create themed maps that are helpful to visualize geospatial data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-geospatial-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-geospatial-data-into-r",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualization with R",
    "section": "2.3.1 Importing Geospatial Data into R",
    "text": "2.3.1 Importing Geospatial Data into R\nNext, we will import the MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz. Here, we use the st_read() from sf.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/binhui-ong/IS415-GAA/Hands-on_Ex/Hands-on_Ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe can examine the content of mpsz with the following code chunk.:\n\nmpsz \n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nThe code chunk allows us to have a quick understanding of the data by displaying only the first 10, out of 323, records."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-attribute-aspatial-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-attribute-aspatial-data-into-r",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualization with R",
    "section": "2.3.2 Importing Attribute (Aspatial) Data into R",
    "text": "2.3.2 Importing Attribute (Aspatial) Data into R\nNext, we would be importing into the respopagesextod2011to2020.csv file into R.\nWe will use read_csv() from the readr package and save it as a data frame called popdata.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-preparation",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualization with R",
    "section": "2.3.3 Data Preparation",
    "text": "2.3.3 Data Preparation\nIn this exercise, we aim to use the attribute data that only has year 2020 values, with variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY, where\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group.\n\nIn the following two sub-sections, we will prepare the relevant attribute data, and combine it with the geospatial data to produce a new data frame for our map production.\n\n2.3.3.1. Data wrangling\nWe will use the following data wrangling and transformation functions to extract the relevant data.\n\npivot_wider() of tidyr package, and mutate(), filter(), group_by()\nselect() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[14])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+\nrowSums(.[15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\nNext, before conducting the join, we must convert the values in PA and SZ fields in the attribute data to uppercase. This is because the fields are currently in a mix of upper- and lowercase, while in the geospatial data, SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 |&gt;\n  mutate_at(.vars= vars(`PA`, `SZ`), .funs = list(toupper))\n\npopdata2020\n\n# A tibble: 332 × 7\n   PA         SZ                   YOUNG `ECONOMY ACTIVE`  AGED TOTAL DEPENDENCY\n   &lt;chr&gt;      &lt;chr&gt;                &lt;dbl&gt;            &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1 ANG MO KIO ANG MO KIO TOWN CEN…  1290             2760   760  4810      0.743\n 2 ANG MO KIO CHENG SAN             5640            16460  6050 28150      0.710\n 3 ANG MO KIO CHONG BOON            5100            15000  6470 26570      0.771\n 4 ANG MO KIO KEBUN BAHRU           4620            13010  5120 22750      0.749\n 5 ANG MO KIO SEMBAWANG HILLS       1880             3630  1310  6820      0.879\n 6 ANG MO KIO SHANGRI-LA            3330             9050  3610 15990      0.767\n 7 ANG MO KIO TAGORE                1940             4480  1530  7950      0.775\n 8 ANG MO KIO TOWNSVILLE            4190            11950  5100 21240      0.777\n 9 ANG MO KIO YIO CHU KANG             0                0     0     0    NaN    \n10 ANG MO KIO YIO CHU KANG EAST     1110             2410   750  4270      0.772\n# ℹ 322 more rows\n\n\n\n\n2.3.3.2 Joining the geospatial and attribute data\nNow, we are ready to combine the geospatial and attribute data! For this step, we use left_join() from the dplyr package to join the attribute data to the geographical data, using planning subzone name (i.e SUBZONE_N and SZ) as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz,popdata2020, by = c(\"SUBZONE_N\" = \"SZ\"))\n\nAs the output follows the format of the left data frame in left_join, using mpsz as our left data table ensures that the output would also be a simple feature data frame.\nNow that we are almost done with our data preparation, the last step is to save the data as a file in our directory for future use.\nTo do so, we must create a new folder “rds” in our directory. Thereafter, we apply the code chunk below.\n\nwrite_rds(mpsz_pop2020,\"data/rds/mpsz_popdata2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#approach-1-plot-a-choropleth-map-quickly-using-qtm",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#approach-1-plot-a-choropleth-map-quickly-using-qtm",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualization with R",
    "section": "2.4.1 Approach 1: Plot a choropleth map quickly using qtm()",
    "text": "2.4.1 Approach 1: Plot a choropleth map quickly using qtm()\nThis approach uses tmap to draw a choropleth map simply and quickly. It is concise and give a good default visualization in many cases.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, fill = \"DEPENDENCY\")\n\n\n\n\nIn the above code, tmap_mode() with “plot” input produces a static map. To produce an interactive map, we should use “view” input.\nAdditionally, the fill argument is used to map the attribute.\nNonetheless, this approach limits our ability to customize the map. To create a high quality cartographic choropleth map, we should use tmap’s drawing elements shown in the following Approach 2."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#approach-2-creating-a-choropleth-map-using-tmaps-elements",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#approach-2-creating-a-choropleth-map-using-tmaps-elements",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualization with R",
    "section": "2.4.2 Approach 2: Creating a choropleth map using tmap’s elements",
    "text": "2.4.2 Approach 2: Creating a choropleth map using tmap’s elements\nThe second approach involves adding tmap’s elements layer by layer to create a high quality cartographic choropleth map like the one below. It also allows us to customize various details of the map such as fill and border transparency, and title position through options (such as “alpha=” for fill transparency) within the functions to best suit our aesthetic needs.\nIt is more complicated and lengthy, but definitely rewarding when we want a beautiful graph!\n\n\n\n\n\nSteps\nStep 1: Draw a base map\nTo begin, we would need to input the basic building block of tmap, which is tm_shape(). Thereafter, we add layers of elements such as tm_polygons() (or tm_fills() which will be shown later) to assign the target variable.\n\ntm_shape(mpsz_pop2020) +\n    tm_polygons()\n\n\n\n\nStep 2: Assigning target variable to tm_polygons()\nSince our target variable is “DEPENDENCY”, we would assign it to tm_polygons(). It will create a map with borders within the map and fills to represent the target variable.\n\ntm_shape(mpsz_pop2020) +\n    tm_polygons(\"DEPENDENCY\")\n\n\n\n\nNote: If we want to adjust the transparency of the borders or fills, we can do so with the border.alpha and alpha options respectively.\nAlternative to tm_polygons(): tm_fills() and tm_borders()\nIn a case in which we do not want the borders within the map, we can use tm_fill() instead of tm_polygons.\n\ntm_shape(mpsz_pop2020) +\n    tm_fill(\"DEPENDENCY\")\n\n\n\n\nThen, if we want to include the borders too, we can add a layer with tm_borders().\nThe combination of tm_fill() and tm_borders() would results in the same map as that with tm_polygons() in the first code chunk of this step (shown earlier on).\n\ntm_shape(mpsz_pop2020) +\n    tm_fill(\"DEPENDENCY\") +\n  tm_borders(col= \"tomato\", lwd = 0.2, alpha =0.8, lty = \"dashed\")\n\n\n\n\nThe above is an example of how we made some adjustments to the appearance of the borders:\n\nborder color: “tomato”\nborder line width (lwd): 0.1\nborder transparency: 0.9 (where 0 = completely transparent and 1 = completely opaque)\nborder line type: dashed"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-classification-methods-of-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-classification-methods-of-tmap",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualization with R",
    "section": "2.4.3 Data classification methods of tmap",
    "text": "2.4.3 Data classification methods of tmap\n\n2.4.3.1 Plotting choropleth maps using built-in classification methods\nMost choropleth maps use some methods of data classification to group a large number of observations into data ranges or classes.\ntmap provides a total of ten data classification methods for our needs, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, jenks\nTo define a data classification method, the style option in tm_polygons() or tm_fill() can be applied.\nIn the following examples, I will be using tm_polygons() to exhibit how different data classifications and different number of classes can affect the maps produced.\nExample 1: Different data classification with the same number of classes\nData classification with quantile data classification that uses 5 classes\n\ntm_shape(mpsz_pop2020) + \n  tm_polygons(\"DEPENDENCY\", style = \"quantile\", n=5)\n\n\n\n\nData classification with equal data classification that uses 5 classes\n\ntm_shape(mpsz_pop2020) + \n  tm_polygons(\"DEPENDENCY\", style = \"equal\", n=5)\n\n\n\n\nFrom the maps generated by the two different data classification methods, we can see that the quantile data classification method produces a more evenly distribution compared to the equal data classification method, even though they have the same number of classes.\nExample 2: Data classification with the same data classification, using different number of classes\nData classification with equal data classification that uses 4 classes\n\ntm_shape(mpsz_pop2020) + \n  tm_polygons(\"DEPENDENCY\", style = \"equal\", n=4)\n\n\n\n\nData classification with equal data classification that uses 10 classes\n\ntm_shape(mpsz_pop2020) + \n  tm_polygons(\"DEPENDENCY\", style = \"equal\", n=10)\n\n\n\n\nFrom the maps generated by the two different number of classes, we can see that using 4 classes produces a more evenly distribution compared to using 10 classes, even though they employ the same data classification method.\nIn summary, it is important to note that our choice of data classification and classes can significantly affect the distribution in maps, which can in turn affect the reader’s insights drawn from the map, especially at first glance.\n\n\n2.4.3.2 Plotting choropleth maps with customized breaks\nFor all built-in styles, the category breaks are computed internally. To set particular breaks, the breakpoints can be set explicitly using the “breaks=” argument in tm_polygons() or tm_fill().\nIt is important to note that in tmap, the breaks include minimum and maximum points. Hence, for n categories, we must have (n+1) elements in the “breaks=” option, in increasing order.\nBefore we begin, we should attain some descriptive statistics to get an idea of where we should set our break points. To compute the descriptive statistics of “DEPENDENCY” field, we apply the following code.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6519  0.7025  0.7742  0.7645 19.0000      92 \n\n\nFrom the descriptive statistics, we can reasonably set break points at 0.60, 0.70, 0.80 and 0.90, and include our minimum point as 0 and maximum point as 100. The resulting breaks vector is c(0, 0.60, 0.70, 0.80, 0.90).\n\ntm_shape(mpsz_pop2020) + \n  tm_polygons(\"DEPENDENCY\", breaks = c(0, 0.60, 0.70, 0.80, 0.90)) \n\n\n\n\nAs we can see, setting our own breaks has appeared to create a more meaningful representation of the distribution. Hence, when classifying data, we should compare this method with the built-in functions method (section 2.4.3.1) and employ the method that produces a more meaningful result."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#color-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#color-scheme",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualization with R",
    "section": "2.4.4 Color Scheme",
    "text": "2.4.4 Color Scheme\ntmap supports color ramps defined by the user or a set of predefined color ramps from the RColorBrewer package.\n\n2.4.4.1 Using ColorBrewer palette\nTo change the color, we assign the preferred color to the palette option of tm_polygons() or tm_fill(). For instance, in the code chunk below, we assign “Blues” to the palette argument tm_polygons.\n\ntm_shape(mpsz_pop2020) + \n  tm_polygons(\"DEPENDENCY\", \n          n=6,\n          style = \"quantile\", \n          palette = \"Blues\")\n\n\n\n\nTo reverse the color shading, we add a “-” prefix to the color.\n\ntm_shape(mpsz_pop2020) + \n  tm_polygons(\"DEPENDENCY\", \n          n=6,\n          style = \"quantile\", \n          palette = \"-Blues\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#map-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#map-layouts",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualization with R",
    "section": "2.4.5 Map Layouts",
    "text": "2.4.5 Map Layouts\nMap layout refers to the combination of all map elements into a cohesive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Color settings and data classification methods covered in the previous section related to the palette and break-points are used to affect how the map looks.\n\n2.4.5.1 Map Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020) + \n  tm_polygons(\"DEPENDENCY\", \n              border.alpha = 0.5, \n              style = \"jenks\", \n              palette = \"Blues\", \n              legend.hist = TRUE, \n              legend.is.portrait = TRUE, \n              legend.hist.z = 0.1) + \n  tm_layout(main.title = \"Distribution of Dependency Ratio by Planning Subzone (Jenks Classification)\", \n            main.title.position = \"center\", \n            main.title.size = 1, \n            legend.height = 0.35,\n            legend.width = 0.35,\n            legend.outside = FALSE, \n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE)\n\n\n\n\n\n\n2.4.5.2 Map Style\ntmap also allows a wide variety of layout settings to be adjusted. To do so, we can add tmap_style() to the code chunk.\nFor example, to use “classic” style in our map, we apply the following code.\n\ntm_shape(mpsz_pop2020) + \n  tm_polygons(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\",\n          border.alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n2.4.5.3 Cartographic Furniture\nIn addition to map style, tmap also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto to choropleth map.\n\ntm_shape(mpsz_pop2020) + \n  tm_polygons(\"DEPENDENCY\", \n              border.alpha = 0.5, \n              style = \"quantile\", \n              palette = \"Blues\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by Planning Subzone (Quantile Classification)\", \n            main.title.position = \"center\", \n            main.title.size = 1, \n            legend.height = 0.35,\n            legend.width = 0.35,\n            legend.outside = FALSE, \n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) + \n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA) and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nTo reset the default style, we can use:\n\ntmap_style(\"white\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#drawing-small-multiple-choropleth-maps",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#drawing-small-multiple-choropleth-maps",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualization with R",
    "section": "2.4.6 Drawing Small Multiple Choropleth Maps",
    "text": "2.4.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arranged side-by-side, and sometimes stacked vertically. They enable the visualization of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nApproach 1: By assigning multiple values to at least one the aesthetic arguments\nApproach 2: By defining a group-by variable in tm_facets(), and\nApproach 3: By creating multiple stand-alone maps with tmap_arrange().\n\n\n2.4.6.1 Approach 1 ; Assign muliple values to at least one of the aesthetic arguments\nExample 1a: In this example, small multiple choropleth maps are created by defining ncols in tm_polygons().\n\ntm_shape(mpsz_pop2020) + \n  tm_polygons(c(\"YOUNG\", \"AGED\"),\n              style = \"equal\",\n              palette = \"Blues\",\n              border.alpha = 0.5) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"),\n            ) + \n  tmap_style(\"white\")\n\n\n\n\nExample 1b: In this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments.\n\ntm_shape(mpsz_pop2020) + \n  tm_polygons(c(\"DEPENDENCY\", \"AGED\"), \n              style = c(\"equal\", \"quantile\"),\n              palette = list(\"Blues\", \"Greens\")) + \n  tm_layout(legend.position=c(\"right\", \"bottom\"))\n\n\n\n\n\n\n2.4.6.2 Approach 2: Define a group-by variable in tm_facets\nExample 2: In this example, multiple small choropleth maps are created using tm_facets().\n\ntm_shape(mpsz_pop2020) + \n  tm_polygons(\"DEPENDENCY\",\n              style = \"quantile\",\n              palette = \"Blues\",\n              thres.poly = 0,\n              border.alpha = 0.5) + \n  tm_facets(by = \"REGION_N\",\n            free.coords = TRUE,\n            drop.units = TRUE) + \n  tm_layout(legend.show = FALSE, \n            title.position = c(\"center\", \"center\"),\n            title.size = 20)\n\n\n\n\n\n\n2.4.6.3 Approach 3: Create multiple stand-alone maps with tmap_arrange()\nIn this approach, we create different maps and combine them together with tmap_arrange(), in which we can customize how we want to arrange them using the ncol option.\n\nyoungmap &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"YOUNG\", \n              style = \"quantile\",\n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"AGED\", \n              style = \"quantile\",\n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp = 1 ,ncol = 2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#mapping-spatial-object-meeting-a-selection-criterion",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#mapping-spatial-object-meeting-a-selection-criterion",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualization with R",
    "section": "2.4.7 Mapping Spatial Object Meeting a Selection Criterion",
    "text": "2.4.7 Mapping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection function to map spatial objects that meet the selection criterion.\nFor example, if we want to map the “DEPENDENCY” distribution only for the “CENTRAL REGION” of Singapore, we can apply the following code.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\",])+\n  tm_polygons(\"DEPENDENCY\",\n              style = \"quantile\",\n              palette = \"Blues\",\n              legend.hist = TRUE, \n              legend.is.portrait = TRUE,\n              legend.histz = 0.1,\n              border.alpha = 0.5) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.35,\n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#tmap-package",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#tmap-package",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualization with R",
    "section": "2.5.1 tmap package",
    "text": "2.5.1 tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualization with R",
    "section": "2.5.2 Geospatial data wrangling",
    "text": "2.5.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-wrangling-1",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-wrangling-1",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualization with R",
    "section": "2.5.3 Data wrangling",
    "text": "2.5.3 Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions\n\nWith the guide of Professor Kam Tin Seong."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bin Hui’s IS415-Geospatial Analytics and Applications Journal",
    "section": "",
    "text": "Hello, welcome to Bin Hui’s IS415 (Geospatial Analytics and Applications) Journal!\nI am Ong Bin Hui, a penultimate student from the Singapore Management University (SMU)\nThis is the course website of IS415, which I study this term. Please feel free to explore my course work on this website with the navigation pane at the top of this webpage.\nMoreover, to find out more about me, head over to the “About Me” page.\nHave a good day! :)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3: Kernel Density Estimation",
    "section": "",
    "text": "In this exercise, we would be using the following three data sets:\n\nCHILDCARE (geojson format)\n\nA point feature data providing both location and attribute information of childcare centres\nSource: Data.gov.sg\n\nMP14_SUBZONE_WEB_PL (ESRI shapefile format)\n\nA polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data\nSource: Data.gov.sg\n\nCostalOutline (ESRI shapefile format)\n\nA polygon feature data showing the national boundary of Singapore\nSource: SLA\n\n\n\n\n\nIn this exercise, the following five R packages will be used”\n\nsf\nspatspat\nraster\nmaptools\ntmap\n\nTo install and load the packages, we apply the following code:\n\n\nCode\n#|eval: FALSE\npacman::p_load(maptools, sf, raster, spatstat, tmap, tidyverse)\n\n\n\n\n\n\n\nIn this section, we will use st_read() from the sf package to import the three geospatial data sets into R.\n\n\nCode\n#|eval: FALSE\nchildcare_sf &lt;- st_read(dsn = \"data/ChildCareServices.geojson\") %&gt;%\n  st_transform(crs=3414)\n\n\nReading layer `ChildCareServices' from data source \n  `/Users/binhui-ong/IS415-GAA/In-class_Ex/In-class_Ex03/data/ChildCareServices.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\nCode\n#|eval: FALSE\nmpsz_sf &lt;- st_read(dsn=\"data\", layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/binhui-ong/IS415-GAA/In-class_Ex/In-class_Ex03/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\nCode\n#|eval: FALSE\nsg_sf &lt;- st_read(dsn=\"data\", layer = \"MP14_SUBZONE_WEB_PL\") %&gt;% st_union()\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/binhui-ong/IS415-GAA/In-class_Ex/In-class_Ex03/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nAlternatively, to get Coastal Outline sg_sf,\nwe can derive it from mpsz_sf.\n\n\nCode\n#|eval: FALSE\nsg_sf &lt;- mpsz_sf %&gt;% st_union()\n\n\nWe can also use st_combine() (instead of st_union()) to get sg_sf. However, unlike st_union(), internal boundaries are not resolved in st_combine().\n\n\nCode\n#|eval: FALSE\nsg_sf &lt;- mpsz_sf %&gt;% st_combine()\n\n\nLet’s examine how the mpsz_sf data set looks like on a map.\n\n\nCode\nplot(mpsz_sf)\n\n\n\n\n\n\n\nCode\nplot(sg_sf)\n\n\n\n\n\n\n\n\nNext, we will use as.ppp() from spatstat package to convert the spatial data into spatstat’s ppp object format:\n\n\nCode\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\n\n\n\n\nWe can check the duplication in a ppp object by using the following code chunk:\n\n\nCode\nany(duplicated(childcare_ppp))\n\n\n[1] FALSE\n\n\nFrom the above, we see that there is no duplicated point.\nHowever, suppose there are duplicated points, to count the number of co-incidence points, we will use multiplicity() function as shown in the code chunk below.\nTo find out how many locations have more than one point event, we can use the code:\n\n\nCode\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n\n[1] 0\n\n\nTo overcome the issue of duplicate points, we can use any of the following 3 solutions:\n\nDelete the duplicates (however, this would lead to the loss of some useful point events)\nJittering: To add a small pertubation to the duplicate points, so that they do not occupy the exact same space\nMake each point “unique”, and attach the duplicates of the points to the patterns as marks, as attributes of the points. Then, we would need analytical techniques that take into account these marks.\n\n\n\nCode\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE,\n                             nsim = 1,\n                             drop = TRUE)\n\n\n\n\nCode\nany(duplicated(childcare_ppp_jit))\n\n\n[1] FALSE\n\n\nThereafter, we should expect no more duplicated points.\n\n\n\nWe can use as.owin(). Note that the object in as.owin() must be an sf object.\n\n\nCode\nsg_owin &lt;- as.owin(sg_sf)\n\n\n\n\n\nTo extract our study areas, we use the filter() function from dplyr package. Do note that this code would only apply on sf objects.\n\n\nCode\npg &lt;- mpsz_sf %&gt;% \n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;% \n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;% \n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;% \n  filter(PLN_AREA_N == \"JURONG WEST\")\n\n\nPlotting target planning areas:\n\n\nCode\npar(mfrow = c(2,2))\nplot(pg, main = \"Punggol\")\n\n\n\n\n\nCode\nplot(tm, main = \"Tampines\")\n\n\n\n\n\nCode\nplot(ck, main= \"Choa Chu Kang\")\n\n\n\n\n\nCode\nplot(jw, main = \"Jurong West\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#data-acquisition",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#data-acquisition",
    "title": "In-class Exercise 3: Kernel Density Estimation",
    "section": "",
    "text": "In this exercise, we would be using the following three data sets:\n\nCHILDCARE (geojson format)\n\nA point feature data providing both location and attribute information of childcare centres\nSource: Data.gov.sg\n\nMP14_SUBZONE_WEB_PL (ESRI shapefile format)\n\nA polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data\nSource: Data.gov.sg\n\nCostalOutline (ESRI shapefile format)\n\nA polygon feature data showing the national boundary of Singapore\nSource: SLA"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#installing-and-loading-the-r-packages",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#installing-and-loading-the-r-packages",
    "title": "In-class Exercise 3: Kernel Density Estimation",
    "section": "",
    "text": "In this exercise, the following five R packages will be used”\n\nsf\nspatspat\nraster\nmaptools\ntmap\n\nTo install and load the packages, we apply the following code:\n\n\nCode\n#|eval: FALSE\npacman::p_load(maptools, sf, raster, spatstat, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#spatial-data-wrangling",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#spatial-data-wrangling",
    "title": "In-class Exercise 3: Kernel Density Estimation",
    "section": "",
    "text": "In this section, we will use st_read() from the sf package to import the three geospatial data sets into R.\n\n\nCode\n#|eval: FALSE\nchildcare_sf &lt;- st_read(dsn = \"data/ChildCareServices.geojson\") %&gt;%\n  st_transform(crs=3414)\n\n\nReading layer `ChildCareServices' from data source \n  `/Users/binhui-ong/IS415-GAA/In-class_Ex/In-class_Ex03/data/ChildCareServices.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\nCode\n#|eval: FALSE\nmpsz_sf &lt;- st_read(dsn=\"data\", layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/binhui-ong/IS415-GAA/In-class_Ex/In-class_Ex03/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\nCode\n#|eval: FALSE\nsg_sf &lt;- st_read(dsn=\"data\", layer = \"MP14_SUBZONE_WEB_PL\") %&gt;% st_union()\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/binhui-ong/IS415-GAA/In-class_Ex/In-class_Ex03/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nAlternatively, to get Coastal Outline sg_sf,\nwe can derive it from mpsz_sf.\n\n\nCode\n#|eval: FALSE\nsg_sf &lt;- mpsz_sf %&gt;% st_union()\n\n\nWe can also use st_combine() (instead of st_union()) to get sg_sf. However, unlike st_union(), internal boundaries are not resolved in st_combine().\n\n\nCode\n#|eval: FALSE\nsg_sf &lt;- mpsz_sf %&gt;% st_combine()\n\n\nLet’s examine how the mpsz_sf data set looks like on a map.\n\n\nCode\nplot(mpsz_sf)\n\n\n\n\n\n\n\nCode\nplot(sg_sf)\n\n\n\n\n\n\n\n\nNext, we will use as.ppp() from spatstat package to convert the spatial data into spatstat’s ppp object format:\n\n\nCode\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\n\n\n\n\nWe can check the duplication in a ppp object by using the following code chunk:\n\n\nCode\nany(duplicated(childcare_ppp))\n\n\n[1] FALSE\n\n\nFrom the above, we see that there is no duplicated point.\nHowever, suppose there are duplicated points, to count the number of co-incidence points, we will use multiplicity() function as shown in the code chunk below.\nTo find out how many locations have more than one point event, we can use the code:\n\n\nCode\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n\n[1] 0\n\n\nTo overcome the issue of duplicate points, we can use any of the following 3 solutions:\n\nDelete the duplicates (however, this would lead to the loss of some useful point events)\nJittering: To add a small pertubation to the duplicate points, so that they do not occupy the exact same space\nMake each point “unique”, and attach the duplicates of the points to the patterns as marks, as attributes of the points. Then, we would need analytical techniques that take into account these marks.\n\n\n\nCode\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE,\n                             nsim = 1,\n                             drop = TRUE)\n\n\n\n\nCode\nany(duplicated(childcare_ppp_jit))\n\n\n[1] FALSE\n\n\nThereafter, we should expect no more duplicated points.\n\n\n\nWe can use as.owin(). Note that the object in as.owin() must be an sf object.\n\n\nCode\nsg_owin &lt;- as.owin(sg_sf)\n\n\n\n\n\nTo extract our study areas, we use the filter() function from dplyr package. Do note that this code would only apply on sf objects.\n\n\nCode\npg &lt;- mpsz_sf %&gt;% \n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;% \n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;% \n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;% \n  filter(PLN_AREA_N == \"JURONG WEST\")\n\n\nPlotting target planning areas:\n\n\nCode\npar(mfrow = c(2,2))\nplot(pg, main = \"Punggol\")\n\n\n\n\n\nCode\nplot(tm, main = \"Tampines\")\n\n\n\n\n\nCode\nplot(ck, main= \"Choa Chu Kang\")\n\n\n\n\n\nCode\nplot(jw, main = \"Jurong West\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#installing-and-loading-r-packages",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#installing-and-loading-r-packages",
    "title": "In-class Exercise 3: Kernel Density Estimation",
    "section": "2.1 Installing and Loading R Packages",
    "text": "2.1 Installing and Loading R Packages\n\n\nCode\n#|eval: FALSE\npacman::p_load(sp ,sf, spNetwork, tmap, classInt, viridis, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#data-import",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#data-import",
    "title": "In-class Exercise 3: Kernel Density Estimation",
    "section": "2.2 Data Import",
    "text": "2.2 Data Import\n\n\nCode\n#|eval: FALSE\nnetwork &lt;- st_read(dsn = \"data 1/geospatial\", \n                   layer = \"Punggol_St\")\n\n\nReading layer `Punggol_St' from data source \n  `/Users/binhui-ong/IS415-GAA/In-class_Ex/In-class_Ex03/data 1/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2642 features and 2 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 34038.56 ymin: 40941.11 xmax: 38882.85 ymax: 44801.27\nProjected CRS: SVY21 / Singapore TM\n\n\nCode\nchildcare &lt;- st_read(dsn = \"data 1/geospatial\",\n                     layer = \"Punggol_CC\")\n\n\nReading layer `Punggol_CC' from data source \n  `/Users/binhui-ong/IS415-GAA/In-class_Ex/In-class_Ex03/data 1/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\n\n\nWe can examine the structure of the output SpatialDataFrame in RStudio.\nAlternatively, the code chunk below can be used to print the content of network SpatialLineDataFrame and childcare SpatialPointsDataFrame.\n\n\nCode\nstr(network)\n\n\nClasses 'sf' and 'data.frame':  2642 obs. of  3 variables:\n $ LINK_ID : num  1.16e+08 1.16e+08 1.16e+08 1.16e+08 1.16e+08 ...\n $ ST_NAME : chr  \"PUNGGOL RD\" \"PONGGOL TWENTY-FOURTH AVE\" \"PONGGOL SEVENTEENTH AVE\" \"PONGGOL SEVENTEENTH AVE\" ...\n $ geometry:sfc_LINESTRING of length 2642; first list element:  'XY' num [1:2, 1:2] 36547 36559 44575 44614\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA\n  ..- attr(*, \"names\")= chr [1:2] \"LINK_ID\" \"ST_NAME\"\n\n\nCode\nstr(childcare)\n\n\nClasses 'sf' and 'data.frame':  61 obs. of  2 variables:\n $ Name    : chr  \"kml_10\" \"kml_99\" \"kml_100\" \"kml_101\" ...\n $ geometry:sfc_POINT of length 61; first list element:  'XYZ' num  36174 42550 0\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA\n  ..- attr(*, \"names\")= chr \"Name\""
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#geospatial-data-visualization",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#geospatial-data-visualization",
    "title": "In-class Exercise 3: Kernel Density Estimation",
    "section": "2.3 Geospatial Data Visualization",
    "text": "2.3 Geospatial Data Visualization\nTo visualise geospatial data in a high cartographic quality and interactive manner, the mapping function of tmap package can be used as shown in the code chunk below.\n\n\nCode\ntmap_mode('view')\ntm_shape(childcare) + \ntm_dots()+\ntm_shape(network) + \ntm_lines()\n\n\n\n\n\n\n\nCode\ntmap_mode('plot')"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#network-constrained-kde-netkde-analysis",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#network-constrained-kde-netkde-analysis",
    "title": "In-class Exercise 3: Kernel Density Estimation",
    "section": "2.4 Network Constrained KDE (NetKDE) Analysis",
    "text": "2.4 Network Constrained KDE (NetKDE) Analysis\nIn this section, we will perform NetKDE analysis by using appropriate functions provided in spNetwork package.\n\n2.4.1 Preparing the lixels objects\nBefore computing NetKDE, the SpatialLines object need to be cut into lixels with a specified minimal distance. This task can be performed by using with lixelize_lines() of spNetwork as shown in the code chunk below.\n\n\nCode\nlixels &lt;- lixelize_lines(network,\n                         750,\n                         mindist = 375)\n\n\n\n\n2.4.2 Generating line centre points\n\n\nCode\nsamples &lt;- lines_center(lixels)\n\n\n\n\n2.4.3 Performing NetKDE\nWe can compute the NetKDE by using the code chunk below:\n\n\nCode\ndensities &lt;- nkde(network, \n                  events = childcare,\n                  w = rep(1,nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, \n                  sparse = TRUE,\n                  verbose = FALSE)\n\n\n\n\n2.4.3.1 Visualizing NetKDE\nBefore we can visualise the NetKDE values, code chunk below will be used to insert the computed density values (i.e. densities) into samples and lixels objects as density field.\n\n\nCode\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\n\nRescaling to help mapping:\n\n\nCode\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\n\nThe code below uses appropriate functions of tmap package to prepare interactive and high cartographic quality map visualisation.\n\n\nCode\ntmap_mode('view')\ntm_shape(lixels)+\n  tm_lines(col=\"density\")+\ntm_shape(childcare)+\n  tm_dots()"
  }
]