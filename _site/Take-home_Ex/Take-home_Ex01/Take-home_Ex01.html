<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2024-01-23">

<title>Bin Hui’s IS415-GAA Journal - (NOT DONE) Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Bin Hui’s IS415-GAA Journal</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-hands-on-exercise" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Hands-on Exercise</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-hands-on-exercise">    
        <li>
    <a class="dropdown-item" href="../../Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html" rel="" target="">
 <span class="dropdown-text">Hands-on Exercise 1</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html" rel="" target="">
 <span class="dropdown-text">Hands-on Exercise 2</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html" rel="" target="">
 <span class="dropdown-text">Hands-on Exercise 3</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html" rel="" target="">
 <span class="dropdown-text">Hands-on Exercise 4</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html" rel="" target="">
 <span class="dropdown-text">Hands-on Exercise 5</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html" rel="" target="">
 <span class="dropdown-text">Hands-on Exercise 6</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html" rel="" target="">
 <span class="dropdown-text">Hands-on Exercise 7</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-in-class-exercise" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">In-class Exercise</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-in-class-exercise">    
        <li>
    <a class="dropdown-item" href="../../In-class_Ex/In-class_Ex02/In-class_Ex02.html" rel="" target="">
 <span class="dropdown-text">In-class Exercise 2</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../In-class_Ex/In-class_Ex03/In-class_Ex03.html" rel="" target="">
 <span class="dropdown-text">In-class Exercise 3</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../In-class_Ex/In-class_Ex04/In-class_Ex04.html" rel="" target="">
 <span class="dropdown-text">In-class Exercise 4</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../In-class_Ex/In-class_Ex05/In-class_Ex05.html" rel="" target="">
 <span class="dropdown-text">In-class Exercise 5</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../In-class_Ex/In-class_Ex06/In-class_Ex06.html" rel="" target="">
 <span class="dropdown-text">In-class Exercise 6</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../In-class_Ex/In-class_Ex07/In-class_Ex07.html" rel="" target="">
 <span class="dropdown-text">In-class Exercise 6</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-take-home-exercise" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Take-home Exercise</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-take-home-exercise">    
        <li class="dropdown-header">Take-home Exercise 1</li>
        <li>
    <a class="dropdown-item" href="../../Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html" rel="" target="">
 <span class="dropdown-text"></span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About Me</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">1 Overview</a>
  <ul class="collapse">
  <li><a href="#background" id="toc-background" class="nav-link" data-scroll-target="#background">1.1 Background</a></li>
  <li><a href="#our-objectives" id="toc-our-objectives" class="nav-link" data-scroll-target="#our-objectives">1.2 Our Objectives</a></li>
  <li><a href="#our-task" id="toc-our-task" class="nav-link" data-scroll-target="#our-task">1.3 Our Task</a></li>
  <li><a href="#data-acquisition" id="toc-data-acquisition" class="nav-link" data-scroll-target="#data-acquisition">1.4 Data Acquisition</a></li>
  <li><a href="#install-and-load-r-packages" id="toc-install-and-load-r-packages" class="nav-link" data-scroll-target="#install-and-load-r-packages">1.5 Install and Load R Packages</a></li>
  </ul></li>
  <li><a href="#data-preparation-geospatial" id="toc-data-preparation-geospatial" class="nav-link" data-scroll-target="#data-preparation-geospatial">2 Data Preparation (Geospatial)</a>
  <ul class="collapse">
  <li><a href="#data-import" id="toc-data-import" class="nav-link" data-scroll-target="#data-import">2.1 Data Import</a></li>
  <li><a href="#data-preparation" id="toc-data-preparation" class="nav-link" data-scroll-target="#data-preparation">2.2 Data Preparation</a>
  <ul class="collapse">
  <li><a href="#data-pre-processing" id="toc-data-pre-processing" class="nav-link" data-scroll-target="#data-pre-processing">2.2.1 Data Pre-Processing</a></li>
  <li><a href="#verifying-and-transforming-crs" id="toc-verifying-and-transforming-crs" class="nav-link" data-scroll-target="#verifying-and-transforming-crs">2.2.2 Verifying and Transforming CRS</a></li>
  <li><a href="#extraction-of-relevant-data" id="toc-extraction-of-relevant-data" class="nav-link" data-scroll-target="#extraction-of-relevant-data">2.2.3 Extraction of relevant data</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#data-preparation-aspatial" id="toc-data-preparation-aspatial" class="nav-link" data-scroll-target="#data-preparation-aspatial">3 Data Preparation (Aspatial)</a>
  <ul class="collapse">
  <li><a href="#importing-aspatial-data" id="toc-importing-aspatial-data" class="nav-link" data-scroll-target="#importing-aspatial-data">3.1 Importing Aspatial Data</a></li>
  <li><a href="#data-preparation-1" id="toc-data-preparation-1" class="nav-link" data-scroll-target="#data-preparation-1">3.1 Data Preparation</a>
  <ul class="collapse">
  <li><a href="#changing-data-types" id="toc-changing-data-types" class="nav-link" data-scroll-target="#changing-data-types">3.1.1 Changing Data Types</a></li>
  <li><a href="#conversion-into-sf-tibble-data-frame" id="toc-conversion-into-sf-tibble-data-frame" class="nav-link" data-scroll-target="#conversion-into-sf-tibble-data-frame">3.1.2 Conversion into sf tibble data frame</a></li>
  <li><a href="#verifying-and-transforming-crs-1" id="toc-verifying-and-transforming-crs-1" class="nav-link" data-scroll-target="#verifying-and-transforming-crs-1">3.1.3 Verifying and Transforming CRS</a></li>
  <li><a href="#extracting-study-data" id="toc-extracting-study-data" class="nav-link" data-scroll-target="#extracting-study-data">3.1.4 Extracting Study Data</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#joining-geospatial-and-aspatial-data-to-kiv" id="toc-joining-geospatial-and-aspatial-data-to-kiv" class="nav-link" data-scroll-target="#joining-geospatial-and-aspatial-data-to-kiv">4 Joining Geospatial and Aspatial Data (TO KIV)</a></li>
  <li><a href="#exploratory-data-analysis-eda-and-choropleth-mapping" id="toc-exploratory-data-analysis-eda-and-choropleth-mapping" class="nav-link" data-scroll-target="#exploratory-data-analysis-eda-and-choropleth-mapping">5 Exploratory Data Analysis (EDA) and Choropleth Mapping</a>
  <ul class="collapse">
  <li><a href="#days-of-the-week" id="toc-days-of-the-week" class="nav-link" data-scroll-target="#days-of-the-week">5.1 Days of the Week</a></li>
  <li><a href="#peak-times" id="toc-peak-times" class="nav-link" data-scroll-target="#peak-times">5.2 Peak Times</a></li>
  <li><a href="#mapping-the-geospatial-data-sets" id="toc-mapping-the-geospatial-data-sets" class="nav-link" data-scroll-target="#mapping-the-geospatial-data-sets">5.3 Mapping the geospatial data sets</a></li>
  </ul></li>
  <li><a href="#first-order-spatial-point-patterns-analysis-sppa" id="toc-first-order-spatial-point-patterns-analysis-sppa" class="nav-link" data-scroll-target="#first-order-spatial-point-patterns-analysis-sppa">6 First-order Spatial Point Patterns Analysis (SPPA)</a>
  <ul class="collapse">
  <li><a href="#geospatial-data-wrangling-for-first-order-sppa" id="toc-geospatial-data-wrangling-for-first-order-sppa" class="nav-link" data-scroll-target="#geospatial-data-wrangling-for-first-order-sppa">6.1 Geospatial Data Wrangling for First-order SPPA</a>
  <ul class="collapse">
  <li><a href="#converting-sf-data-frames-to-sps-spatial-class" id="toc-converting-sf-data-frames-to-sps-spatial-class" class="nav-link" data-scroll-target="#converting-sf-data-frames-to-sps-spatial-class">6.1.1 Converting sf data frames to sp’s Spatial class</a></li>
  <li><a href="#converting-the-spatial-class-into-generic-sp-format" id="toc-converting-the-spatial-class-into-generic-sp-format" class="nav-link" data-scroll-target="#converting-the-spatial-class-into-generic-sp-format">6.1.2 Converting the Spatial class into generic sp format</a></li>
  <li><a href="#converting-the-generic-sp-format-into-spatstats-ppp-format" id="toc-converting-the-generic-sp-format-into-spatstats-ppp-format" class="nav-link" data-scroll-target="#converting-the-generic-sp-format-into-spatstats-ppp-format">6.1.3 Converting the generic sp format into spatstat’s ppp format</a></li>
  <li><a href="#handling-duplicated-points" id="toc-handling-duplicated-points" class="nav-link" data-scroll-target="#handling-duplicated-points">6.1.4 Handling duplicated points</a></li>
  <li><a href="#creating-owin-object" id="toc-creating-owin-object" class="nav-link" data-scroll-target="#creating-owin-object">6.1.5 Creating owin object</a></li>
  <li><a href="#combining-point-events-object-and-owin-object" id="toc-combining-point-events-object-and-owin-object" class="nav-link" data-scroll-target="#combining-point-events-object-and-owin-object">6.1.6 Combining point events object and owin object</a></li>
  </ul></li>
  <li><a href="#deriving-traditional-kernel-density-estimation-kde-layers" id="toc-deriving-traditional-kernel-density-estimation-kde-layers" class="nav-link" data-scroll-target="#deriving-traditional-kernel-density-estimation-kde-layers">6.2 Deriving Traditional Kernel Density Estimation (KDE) Layers</a>
  <ul class="collapse">
  <li><a href="#computing-kde-using-automatic-bandwidth-selection-method" id="toc-computing-kde-using-automatic-bandwidth-selection-method" class="nav-link" data-scroll-target="#computing-kde-using-automatic-bandwidth-selection-method">6.2.1 Computing KDE using automatic bandwidth selection method</a></li>
  <li><a href="#rescaling-kde-values" id="toc-rescaling-kde-values" class="nav-link" data-scroll-target="#rescaling-kde-values">6.2.2 Rescaling KDE values</a></li>
  <li><a href="#comparing-different-automatic-bandwidth-methods" id="toc-comparing-different-automatic-bandwidth-methods" class="nav-link" data-scroll-target="#comparing-different-automatic-bandwidth-methods">6.2.3 Comparing different automatic bandwidth methods</a></li>
  <li><a href="#comparing-different-kernel-methods" id="toc-comparing-different-kernel-methods" class="nav-link" data-scroll-target="#comparing-different-kernel-methods">6.2.4 Comparing different kernel methods</a></li>
  <li><a href="#fixed-and-adaptive-kde" id="toc-fixed-and-adaptive-kde" class="nav-link" data-scroll-target="#fixed-and-adaptive-kde">6.2.5 Fixed and Adaptive KDE</a></li>
  <li><a href="#converting-kde-output-into-grid-object" id="toc-converting-kde-output-into-grid-object" class="nav-link" data-scroll-target="#converting-kde-output-into-grid-object">6.2.6 Converting KDE output into grid object</a></li>
  <li><a href="#converting-gridded-output-into-raster" id="toc-converting-gridded-output-into-raster" class="nav-link" data-scroll-target="#converting-gridded-output-into-raster">6.2.7 Converting gridded output into raster</a></li>
  <li><a href="#assigning-projection-systems-if-necessary" id="toc-assigning-projection-systems-if-necessary" class="nav-link" data-scroll-target="#assigning-projection-systems-if-necessary">6.2.8 Assigning projection systems (if necessary)</a></li>
  <li><a href="#visualizing-the-output-in-tmap" id="toc-visualizing-the-output-in-tmap" class="nav-link" data-scroll-target="#visualizing-the-output-in-tmap">6.2.9 Visualizing the output in tmap</a></li>
  </ul></li>
  <li><a href="#deriving-network-kernel-density-estimation-netkde-layers" id="toc-deriving-network-kernel-density-estimation-netkde-layers" class="nav-link" data-scroll-target="#deriving-network-kernel-density-estimation-netkde-layers">6.3 Deriving Network Kernel Density Estimation (NetKDE) Layers</a>
  <ul class="collapse">
  <li><a href="#preparing-the-lixels-objects" id="toc-preparing-the-lixels-objects" class="nav-link" data-scroll-target="#preparing-the-lixels-objects">6.3.1 Preparing the lixels objects</a></li>
  <li><a href="#generating-line-centre-points" id="toc-generating-line-centre-points" class="nav-link" data-scroll-target="#generating-line-centre-points">6.3.2 Generating line centre points</a></li>
  <li><a href="#performing-netkde" id="toc-performing-netkde" class="nav-link" data-scroll-target="#performing-netkde">6.3.3 Performing NetKDE</a></li>
  <li><a href="#visualizing-netkde" id="toc-visualizing-netkde" class="nav-link" data-scroll-target="#visualizing-netkde">6.3.4 Visualizing NetKDE</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">(NOT DONE) Take-home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of Grab hailing services in Singapore</h1>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 23, 2024</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="overview" class="level1">
<h1>1 Overview</h1>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">1.1 Background</h2>
<p>Human mobility, the movement of human beings in space and time, reflects the spatial-temporal characteristics of human behavior. With the advancement Information and Communication Technologies (ICT) especially in smartphones, a large volume of data related to human mobility have been collected. By using appropriate GIS analysis methods, these data are potentially useful in supporting smart city planning and management.</p>
<p>In 2020, a very interesting human mobility data set called Grab Posisi was released by GRAB, one of the largest shared taxi operator in South-east Asia. This provides an opportunity for us to explore the geographical and spatio-temporal distribution of Grab hailing services locations in Singapore.</p>
</section>
<section id="our-objectives" class="level2">
<h2 class="anchored" data-anchor-id="our-objectives">1.2 Our Objectives</h2>
<p>In this exercise, we will be exploring the geographical and spatial-temporal distribution of Grab hailing services locations in Singapore with the use of spatial point patterns analysis techniques.</p>
</section>
<section id="our-task" class="level2">
<h2 class="anchored" data-anchor-id="our-task">1.3 Our Task</h2>
<ul>
<li><p>Use appropriate functions of <strong>sf</strong> and <strong>tidyverse</strong> to prepare the following geospatial data layer in sf tibble data.frames:</p>
<ul>
<li><p>Grab taxi location points either by origins or destinations.</p></li>
<li><p>Road layer within Singapore excluding outer islands.</p></li>
<li><p>Singapore boundary layer excluding outer islands</p></li>
</ul></li>
<li><p>Use the extracted data to derive traditional Kernel Density Estimation layers.</p></li>
<li><p>Use the extracted data to derive either Network Kernel Density Estimation (NKDE) or Temporal Network Kernel Density Estimation (TNKDE)</p></li>
<li><p>Use appropriate <strong>tmap</strong> functions to display the kernel density layers on openstreetmap of Singapore.</p></li>
<li><p>Describe the spatial patterns revealed by the kernel density maps.</p></li>
</ul>
</section>
<section id="data-acquisition" class="level2">
<h2 class="anchored" data-anchor-id="data-acquisition">1.4 Data Acquisition</h2>
<p>To address the above questions, we would be using the following data sets:</p>
<table class="table">
<thead>
<tr class="header">
<th>Type</th>
<th>Content</th>
<th>Source</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Geospatial</td>
<td>Road data set of Malaysia, Singapore and Brunei</td>
<td><a href="https://download.geofabrik.de/">OpenStreetMap of Geofabrik download server</a></td>
</tr>
<tr class="even">
<td>Geospatial</td>
<td>Master Plan 2019 Subzone Boundary (No Sea)</td>
<td><a href="https://beta.data.gov.sg/collections/1749/datasets/d_8594ae9ff96d0c708bc2af633048edfb/view">data.gov.sg</a></td>
</tr>
<tr class="odd">
<td>Aspatial</td>
<td>Grab-Posisi of Singapore</td>
<td><a href="https://engineering.grab.com/grab-posisi">engineering.grab.com</a></td>
</tr>
</tbody>
</table>
</section>
<section id="install-and-load-r-packages" class="level2">
<h2 class="anchored" data-anchor-id="install-and-load-r-packages">1.5 Install and Load R Packages</h2>
<p>In this exercise, the following R packages will be used:</p>
<ul>
<li><p><strong>tidyverse</strong>: to read, manipulate and create tidy data, and to create data graphics</p></li>
<li><p><strong>sf</strong>: to provide simple features access to represent and work with spatial vector data such as points and polygons</p></li>
<li><p><strong>spatstat</strong>: to perform statistical analysis of spatial data</p></li>
<li><p><strong>raster</strong>: to read, write, manipulate, analyze and model spatial data</p></li>
<li><p><strong>maptools</strong>: tools for handling spatial objects</p></li>
<li><p><strong>tmap</strong>: to create thematic and high-quality cartographic maps</p></li>
<li><p><strong>arrow</strong>: improve the performance of data analysis methods, and to increase the efficiency of moving data from one system or programming language to another</p></li>
<li><p><strong>spNetwork</strong>: to perform Spatial Point Patterns Analysis such as kernel density estimation (KDE) and K-function on network. It also can be used to build spatial matrices (‘listw’ objects like in ‘spdep’ package) to conduct any kind of traditional spatial analysis with spatial weights based on reticular distances.</p></li>
<li><p><strong>classInt</strong>: provides a uniform interface to finding class intervals for continuous numerical variables</p></li>
<li><p><strong>viridis</strong>: to create colorblind-friendly maps</p></li>
<li><p><strong>lubridate</strong>: to parse and manipulate dates</p></li>
<li><p><strong>ggplot2</strong></p></li>
</ul>
<p>To install and load the packages, we will use p_load() from the pacman package:</p>
</section>
</section>
<section id="data-preparation-geospatial" class="level1">
<h1>2 Data Preparation (Geospatial)</h1>
<p>Let’s begin getting our hands dirty by introducing and preparing the geospatial data sets in R!</p>
<section id="data-import" class="level2">
<h2 class="anchored" data-anchor-id="data-import">2.1 Data Import</h2>
<p>To import geospatial data, we will be using <strong>st_read()</strong> from the <strong>sf</strong> package.</p>
<p>Road data set from OSM (shapefile format):</p>
<p>Master Plan 2019 Subzone Boundary (No Sea) (geojson format):</p>
</section>
<section id="data-preparation" class="level2">
<h2 class="anchored" data-anchor-id="data-preparation">2.2 Data Preparation</h2>
<p>It is important to ensure our geospatial data is clean, in the correct coordinate reference system (CRS) and extracted to contain only relevant data to prevent complications later on.</p>
<p>In this section, we will go through the procedures to prepare our geospatial data.</p>
<section id="data-pre-processing" class="level3">
<h3 class="anchored" data-anchor-id="data-pre-processing">2.2.1 Data Pre-Processing</h3>
<p>To begin with, let’s examine the data sets to understand their features.</p>
<p>From the above, we can see that roaddata_sf is an sf object, with linestring geometry type and dimension XY.</p>
<p>We also notice that it is in WGS84 geodetic CRS, which is not our desired coordinate reference system (svy 21). Hence, we would have to reproject it later (#### INDICATE SECTION NUMBER).</p>
<p>For mpsz_sf, we see that it is an sf object with multipolygon geometry type. It comprises of records with XYZ coordinates, indicating a Z-dimension, quite redundant to us.</p>
<p>Here, we notice that mpsz_sf has geodetic CRS of WGS84 as well. Hence, we will need to fix the CRS for mpsz_sf later (###INDICATE SECTION NUMBER) as well.</p>
<section id="dropping-z-dimension" class="level4">
<h4 class="anchored" data-anchor-id="dropping-z-dimension">2.2.1.1 Dropping Z-dimension</h4>
<p>After having an understanding of our data sets, we will start to modify them into our desired dimensions and systems.</p>
<p>In this step, we will remove the Z-dimension in mpsz_sf, with the use of st_zm(). st_zm() is a function used to drop or add Z and/or M dimensions, from sf package.</p>
<p>With that, we can see that the mpsz_sf has become two-dimensional (XY).</p>
</section>
<section id="invalid-geometries" class="level4">
<h4 class="anchored" data-anchor-id="invalid-geometries">2.2.1.2 Invalid Geometries</h4>
<p>To check whether our data sets contain invalid geometries, we can apply the following code chunks:</p>
<p>We see that roaddata_sf has no invalid geometry, while mpsz_sf has 6 invalid geometries.</p>
<p>To correct the invalid geometries in mpsz_sf, we can use st_make_valid() from sf package,</p>
<p>and check confirm whether the modified mpsz_sf data set now contains fully valid geometries.</p>
<p>Great! Our geographic data are now cleared of invalid geometries.</p>
</section>
<section id="handling-missing-values" class="level4">
<h4 class="anchored" data-anchor-id="handling-missing-values">2.2.1.3 Handling Missing Values</h4>
<p>Next, we will check for missing values in our geographic data.</p>
<p>Let’s begin with checking roaddata_sf, we can applying the following code chunk.</p>
<p>Wow, there is an absurd 1719007 records with missing values?!</p>
<p>Let’s investigate what could be wrong using View().</p>
<p>From the above, it seems like it is the “ref” field comprises of so many missing values! Let’s try removing it, and check again!</p>
<p>Oh no, it appears that there are still a lot of missing values, particularly in the “name” field. However, we should not delete those records because they are not necessarily redundant: in Singapore, if a road length is less than 60m, it need not be named. Thus, these records might still represent valid roads that are shorter than 60m!</p>
<p>Then, ignoring the missing values in “name” field, let’s check whether there are missing values in the other fields.</p>
<p>Phew, finally! There are no missing values in other fields. Seems like roaddata_sf is cleared of missing values that requires our attention.</p>
<p>Next, let’s check mpsz_sf!</p>
<p>Thankfully, there’s no missing values in mpsz_sf!</p>
<p>Hurray we’re done with resolving the missing values~!</p>
</section>
</section>
<section id="verifying-and-transforming-crs" class="level3">
<h3 class="anchored" data-anchor-id="verifying-and-transforming-crs">2.2.2 Verifying and Transforming CRS</h3>
<p>To check the CRS of the data sets, we can use st_crs() from sf package.</p>
<p>From the above, and as also noticed earlier in Section 2.2.1, the data sets are in the WGS84 CRS. However, in Singapore, we should use the SVY21 CRS (with EPSG code: 3414) as it is more appropriate for our analysis.</p>
<p>To change the CRS of the data sets, we can use st_transform() from sf package, inputting the EPSG code for SVY21 (3414) as the second argument of the function.</p>
<p>Then, let’s confirm that the CRS for the data sets have been correctly modified.</p>
<p>Hooray! Our geospatial data are now in the correct CRS!</p>
</section>
<section id="extraction-of-relevant-data" class="level3">
<h3 class="anchored" data-anchor-id="extraction-of-relevant-data">2.2.3 Extraction of relevant data</h3>
<p>After doing some cleaning of our geospatial data, let’s roughly visualize how they look like:</p>
<p>As expected, roaddata_sf contains the visualization of Malaysia, Singapore and Brunei.</p>
<p>And for mpsz_sf, since it is supposed to contain data of Singapore’s territories, the visualization displays the map for only Singapore.</p>
<p>However, in this exercise, we are interested in the data that includes only Singapore without its outer islands, we will have to remove all outer islands outside of Singapore mainland. Hence, we need to do some manipulation to remove the outer islands.</p>
<p>To begin with, we will remove the outer islands from mpsz_sf first using str_detect() from the <strong>stringr</strong> package and filter() from the <strong>dplyr</strong> package, and name the new data frame mpsz_sgsf</p>
<p>Let’s make a quick plot using qtm() from the <strong>tmap</strong> package to check if we’ve successfully extracted data of Singapore’s data excluding outer islands:</p>
<p>Then, to get Singapore’s boundary layer without outer islands,</p>
<p>Let’s check:</p>
<p>Yay! We’ve gotten the Singapore boundary layer that excludes the outer islands!</p>
<p>Next, to derive the road layers that lie within Singapore, we can use st_intersection() from the <strong>sf</strong> package. Here, we shall form a new data set mpszroadsg_sf which should contain geospatial data with road layers within Singapore, without its outer islands.</p>
<p>Now, let’s check that roadsg_sf contains the road layer only within Singapore by plotting a map!</p>
<p>True enough, this should be how the road system of Singapore, without its outer islands, looks like. YAY!</p>
</section>
</section>
</section>
<section id="data-preparation-aspatial" class="level1">
<h1>3 Data Preparation (Aspatial)</h1>
<p>Now, it’s time to introduce our aspatial data set!</p>
<section id="importing-aspatial-data" class="level2">
<h2 class="anchored" data-anchor-id="importing-aspatial-data">3.1 Importing Aspatial Data</h2>
<p>To import aspatial data, we will be using <strong>read_parquet()</strong> from arrow package.</p>
<p>Let’s take a look at the data frames using glimpse() from</p>
<p>We see that each of the data frames is a tibble data frame, with nine columns, with the same column headers.</p>
<p>To combine all of them into one single data frame named grabposisi, we can use rbind().</p>
<p>Tadah! Our grabposisi data sets are consolidated and ready for further preparation.</p>
</section>
<section id="data-preparation-1" class="level2">
<h2 class="anchored" data-anchor-id="data-preparation-1">3.1 Data Preparation</h2>
<p>Next, let’s examine our new consolidated grabposisi data set.</p>
<section id="changing-data-types" class="level3">
<h3 class="anchored" data-anchor-id="changing-data-types">3.1.1 Changing Data Types</h3>
<p>We see that the pingtimestamp field is in the integer format, when it is a datetime type of data. To convert it into datetime format, we can use the following code:</p>
<p>Now, it is in a more appropriate for interpretation and manipulation later!</p>
</section>
<section id="conversion-into-sf-tibble-data-frame" class="level3">
<h3 class="anchored" data-anchor-id="conversion-into-sf-tibble-data-frame">3.1.2 Conversion into sf tibble data frame</h3>
<p>Next, we should combined the rawlng and rawlat fields grabposisi as coordinates format, so that we can transform them into geometry format as an sf tibble data frame to combine with our geospatial data.</p>
<p>To do so, we should apply the following code:</p>
<p>Then, we will use the code below to convert the grabposisi data into sf tibble data frame with svy21 projection system.</p>
</section>
<section id="verifying-and-transforming-crs-1" class="level3">
<h3 class="anchored" data-anchor-id="verifying-and-transforming-crs-1">3.1.3 Verifying and Transforming CRS</h3>
<p>Before we proceed further, let’s ensure grabposisi_sf is in the correct CRS.</p>
<p>It’s in svy21 projection system, we’re good to move on!</p>
</section>
<section id="extracting-study-data" class="level3">
<h3 class="anchored" data-anchor-id="extracting-study-data">3.1.4 Extracting Study Data</h3>
<p>Considering the fact that we are only interested in the Grab taxi location points by origins in this study, we can apply the following code:</p>
<p>The code might look a bit complicating, but let’s go through this step by step through the pipelines:</p>
<ul>
<li><p>Firstly, we use group_by() from dplyr to group the records according to trajectory IDs, so that records of the same journey are together.</p></li>
<li><p>Then, we use arrange() from dplyr to arrange the records according to time in ascending order. With that, the first record of each group would be the earliest record of the journey, inferring that it is the origin point.</p></li>
<li><p>Next, we use filter() from dplyr to filter each group, keeping only their first row. This allows us to keep only the records relating to the origin points of each journey.</p></li>
<li><p>Lastly, we use mutate() from dplyr, along with wday(), hour() and mday() from lubridate to retrieve the weekdays, start_hr, and day of the week to support our analysis later.</p></li>
</ul>
<p>Tadah! We have successfully extracted the Grab taxi location points by origin.</p>
</section>
</section>
</section>
<section id="joining-geospatial-and-aspatial-data-to-kiv" class="level1">
<h1>4 Joining Geospatial and Aspatial Data (TO KIV)</h1>
<p>Now, we will join our geospatial and aspatial data to conduct further analysis in the later sections!</p>
</section>
<section id="exploratory-data-analysis-eda-and-choropleth-mapping" class="level1">
<h1>5 Exploratory Data Analysis (EDA) and Choropleth Mapping</h1>
<p>In this section, we will conduct some EDA on our aspatial data to gain some rough insights to lead us into</p>
<p>Let’s have a look at how our combined data looks like!</p>
<p>Some questions we might be curious about are: - Which are the peak days of the week to take a Grab ride? - When are the peak times throughout the day to hitch a Grab ride? - Where do many of the Grab rides begin? Are they evenly distributed across Singapore? - If so, when are the peak times and days wh</p>
<section id="days-of-the-week" class="level2">
<h2 class="anchored" data-anchor-id="days-of-the-week">5.1 Days of the Week</h2>
<p>To look at the peak days, we can plot a bar chart using ggplot2.</p>
</section>
<section id="peak-times" class="level2">
<h2 class="anchored" data-anchor-id="peak-times">5.2 Peak Times</h2>
<p>Let’s have a look at how the origin points look like on the Singapore map.</p>
</section>
<section id="mapping-the-geospatial-data-sets" class="level2">
<h2 class="anchored" data-anchor-id="mapping-the-geospatial-data-sets">5.3 Mapping the geospatial data sets</h2>
<p>Next, it is also useful for us to create a pin map to show the spatial patterns of our data.</p>
<p>In this interactive mode, we can navigate and zoom around the map freely. Also, we can query the information of each simple feature (i.e the point) by clicking on it.</p>
<p>Thereafter, we switch back to plot mode as the interactive mode will consume a connection.</p>
</section>
</section>
<section id="first-order-spatial-point-patterns-analysis-sppa" class="level1">
<h1>6 First-order Spatial Point Patterns Analysis (SPPA)</h1>
<section id="geospatial-data-wrangling-for-first-order-sppa" class="level2">
<h2 class="anchored" data-anchor-id="geospatial-data-wrangling-for-first-order-sppa">6.1 Geospatial Data Wrangling for First-order SPPA</h2>
<p>To conduct first-order spatial point analysis on our data, we be using the <strong>spatstat</strong> package. However, the spatstat package requires our data to be in sp’s Spatial classes. In this section, we will convert the sf data frames to sp’s Spatial class.</p>
<section id="converting-sf-data-frames-to-sps-spatial-class" class="level3">
<h3 class="anchored" data-anchor-id="converting-sf-data-frames-to-sps-spatial-class">6.1.1 Converting sf data frames to sp’s Spatial class</h3>
<p>To do so, we would use as_Spatial() from the <strong>sf</strong> package to convert our three geospatial data from sf data frame to sp’s Spatial class.</p>
<p>To look into the information of the three new Spatial classes,</p>
</section>
<section id="converting-the-spatial-class-into-generic-sp-format" class="level3">
<h3 class="anchored" data-anchor-id="converting-the-spatial-class-into-generic-sp-format">6.1.2 Converting the Spatial class into generic sp format</h3>
<p>spatstat requires the analytical sata to be in ppp object form. However, as there is no direct method to convert Spatial classes into ppp objects, we would have to convert the Spatial classes into Spatial objects first.</p>
</section>
<section id="converting-the-generic-sp-format-into-spatstats-ppp-format" class="level3">
<h3 class="anchored" data-anchor-id="converting-the-generic-sp-format-into-spatstats-ppp-format">6.1.3 Converting the generic sp format into spatstat’s ppp format</h3>
<p>Here, we can plot origin_grab_ppp to examine the difference.</p>
<p>For a quick understanding of the summary statistics of the newly created ppp object, we can apply the summary() from base R.</p>
</section>
<section id="handling-duplicated-points" class="level3">
<h3 class="anchored" data-anchor-id="handling-duplicated-points">6.1.4 Handling duplicated points</h3>
<p>In this case, given the nature of our geospatial data (origin points of journeys), we can expect several duplicated points on the map. However,</p>
<p>We can check for duplication in a ppp object using the following code chunk:</p>
<p>To find out the number of coincident points, we use multiplicity() from the <strong>spatstat</strong> package.</p>
<p>To find out how many locations have more than one point event, we can use the following code:</p>
<p>To view the location of the duplicate point events, we can plot origin_grab data with the following code chunk:</p>
<p>From the graph above, we can spot the duplicate point events as the duplicate points overlap, resulting in darker points in the map.</p>
<p>To overcome the issue of duplicate points, we can adopt any of the following 3 solutions:</p>
<ol type="1">
<li><p>Delete the duplicates (however, this would result in the loss of some useful point events)</p></li>
<li><p>Jittering: To add a small perturbation to the duplicate points, so that they do not occupy the exact same space</p></li>
<li><p>Make each point “unique”, and attach the duplicates of the points to the patterns as <strong>marks</strong>, as attributes to the points. Then, we would require analytical techniques that take into account these marks.</p></li>
</ol>
<p>Given the nature of this data set, where there could be many duplicated origin points, wherein these duplicates are also meaningful, we will apply the 2nd solution – jittering.</p>
</section>
<section id="creating-owin-object" class="level3">
<h3 class="anchored" data-anchor-id="creating-owin-object">6.1.5 Creating owin object</h3>
<p>When analyzing spatial potterns, it is good practice to confine our analysis within a geograhical area. In <strong>spatstat</strong>, an object called owin is designed to represent this polygonal region.</p>
<p>The following code chunk is used to convert sgboundary_sf into owin object of <strong>spatstat</strong>.</p>
<p>The output object can be displayed by using the plot() function,</p>
<p>and summary() function of BaseR.</p>
</section>
<section id="combining-point-events-object-and-owin-object" class="level3">
<h3 class="anchored" data-anchor-id="combining-point-events-object-and-owin-object">6.1.6 Combining point events object and owin object</h3>
<p>In this last step of geospatial data wrangling, we will extract origin locations that are within Singapore using the following code chunk:</p>
<p>The output object combined both the point and polygon feature in one ppp object class as shown below.</p>
<p>To plot the newly derived originSG_ppp map,</p>
</section>
</section>
<section id="deriving-traditional-kernel-density-estimation-kde-layers" class="level2">
<h2 class="anchored" data-anchor-id="deriving-traditional-kernel-density-estimation-kde-layers">6.2 Deriving Traditional Kernel Density Estimation (KDE) Layers</h2>
<p>In this section, we will be performing first-order SPPA using the <strong>spatstat</strong> package. In particular, we will be deriving the kernel density estimation (KDE) layer for visualizing and exploring the intensity of point processes.</p>
<section id="computing-kde-using-automatic-bandwidth-selection-method" class="level3">
<h3 class="anchored" data-anchor-id="computing-kde-using-automatic-bandwidth-selection-method">6.2.1 Computing KDE using automatic bandwidth selection method</h3>
<p>The code chunk below computed a Kernel Density byy using the following configurations of density() of <strong>spatstat</strong>.</p>
<p>Automatic bandwidth selection method: bw.ppl() - other methods: bw.CvL(), bw.scott() or bw.diggle()</p>
<p>Smoothing kernel: “gaussian” - other methods: “epanechnikov”, “quartic” or “disc”</p>
<p>The intensity estimate is corrected for edge effect bias by using edge = TRUE.</p>
<p>Then, we will plot the derived kernel density.</p>
<section id="the-density-values-of-the-output-range" class="level5">
<h5 class="anchored" data-anchor-id="the-density-values-of-the-output-range">The density values of the output range</h5>
<p>To retrive the bandwidth used to compute the KDE layer, we use the following code chunk:</p>
</section>
</section>
<section id="rescaling-kde-values" class="level3">
<h3 class="anchored" data-anchor-id="rescaling-kde-values">6.2.2 Rescaling KDE values</h3>
<p>In the following code chunk, rescale() is used to convert the unit of measurement from meter to kilometer.</p>
<p>Now, we can re-run density() using the rescaled data set and plot the output KDE map.</p>
<p>Now, we can see that the output image looks identical to the earlier version, but with more intepretable data values in the legend.</p>
</section>
<section id="comparing-different-automatic-bandwidth-methods" class="level3">
<h3 class="anchored" data-anchor-id="comparing-different-automatic-bandwidth-methods">6.2.3 Comparing different automatic bandwidth methods</h3>
<p>Aside from bw.diggle, as mentioned before, there are three other <strong>spatstat</strong> functions (bw.CvL(), bw.scott(), bw.ppl()) that can be used to determine the bandwidth automatically.</p>
<p>Let’s take a look at the bandwidth used by each of these automatic bandwidth calculation methods, keeping all our kernel method (“gaussian”) constant!</p>
<p>The following code chunk is used to compare the difference in output using the different automatic bandwidth methods.</p>
</section>
<section id="comparing-different-kernel-methods" class="level3">
<h3 class="anchored" data-anchor-id="comparing-different-kernel-methods">6.2.4 Comparing different kernel methods</h3>
<p>By default, the kernel method used in density() is Gaussian. However, there are three other available method: Epanechnikov, Quartic and Dics</p>
<p>In the following code chunk, we will compare the different kernel methods, using originSG_ppp.km and automatic bandwidth method bw.ppl.</p>
</section>
<section id="fixed-and-adaptive-kde" class="level3">
<h3 class="anchored" data-anchor-id="fixed-and-adaptive-kde">6.2.5 Fixed and Adaptive KDE</h3>
<section id="computing-kde-by-using-fixed-bandwidth-not-sure-whethet-to-do" class="level4">
<h4 class="anchored" data-anchor-id="computing-kde-by-using-fixed-bandwidth-not-sure-whethet-to-do">6.2.5.1 Computing KDE by using fixed bandwidth (not sure whethet to do)</h4>
<p>Here, we will compute a KDE later by defining a bandwidth of</p>
</section>
<section id="computing-kde-by-using-adaptive-bandwidth" class="level4">
<h4 class="anchored" data-anchor-id="computing-kde-by-using-adaptive-bandwidth">6.2.5.2 Computing KDE by using adaptive bandwidth</h4>
<p>Here, we will derive adaptive KDE using density.adaptive() of <strong>spatstat</strong>.</p>
</section>
</section>
<section id="converting-kde-output-into-grid-object" class="level3">
<h3 class="anchored" data-anchor-id="converting-kde-output-into-grid-object">6.2.6 Converting KDE output into grid object</h3>
</section>
<section id="converting-gridded-output-into-raster" class="level3">
<h3 class="anchored" data-anchor-id="converting-gridded-output-into-raster">6.2.7 Converting gridded output into raster</h3>
<p>Next, we will convert the gridded kernel denstiy objects into RasterLayer object using raster() of <strong>raster</strong> package.</p>
<p>We can look at the properties of this new kde_originSG_bwppl_raster RasterLayer object using the following code chunk:</p>
</section>
<section id="assigning-projection-systems-if-necessary" class="level3">
<h3 class="anchored" data-anchor-id="assigning-projection-systems-if-necessary">6.2.8 Assigning projection systems (if necessary)</h3>
</section>
<section id="visualizing-the-output-in-tmap" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-the-output-in-tmap">6.2.9 Visualizing the output in tmap</h3>
<p>Finally, we will display the raster on openstreetmap of Singapore.</p>
</section>
</section>
<section id="deriving-network-kernel-density-estimation-netkde-layers" class="level2">
<h2 class="anchored" data-anchor-id="deriving-network-kernel-density-estimation-netkde-layers">6.3 Deriving Network Kernel Density Estimation (NetKDE) Layers</h2>
<section id="preparing-the-lixels-objects" class="level3">
<h3 class="anchored" data-anchor-id="preparing-the-lixels-objects">6.3.1 Preparing the lixels objects</h3>
<p>Before computing NetKDE, the roadsg_sp SpatialLines object need to be cut into lixels with a specified minimal distance.</p>
<p>To do so, we can use lixelize_lines() from <strong>spNetwork</strong> package.</p>
<p>In the code chunk above, we have set:</p>
<p>length of lixel, lx_length = 500m</p>
<p>minimum length of lixel, mindist = 200m</p>
<p>Note: After the cut, if the length of the final lixel is shorter than the minimum distance, it would be added to the previous lixel. On the other hand, if mindist is NULL, then mindist = maxdist/10. Segments that are already shorter than the minimum distance are not modified.</p>
</section>
<section id="generating-line-centre-points" class="level3">
<h3 class="anchored" data-anchor-id="generating-line-centre-points">6.3.2 Generating line centre points</h3>
<p>Next, lines_center() of spNetwork will be used to generate a SpatialPointsDataFrame with line centre points as shown below:</p>
</section>
<section id="performing-netkde" class="level3">
<h3 class="anchored" data-anchor-id="performing-netkde">6.3.3 Performing NetKDE</h3>
<p>Next, we will compute the NetKDE using the code chunk below.</p>
<p>From the code chunk above:</p>
<ul>
<li><p>kernel_name argument indicates that quartic kernel is used</p>
<ul>
<li>Other possible kernel methods supported by spNetwork : triangle, gaussian, scaled gaussian, tricube, cosine ,triweight, epanechnikov or uniform.</li>
</ul></li>
<li><p>method argument indicates that simple method is used to calculate the NKDE.</p>
<ul>
<li><p>Currently, spNetwork support three popular methods:</p>
<ul>
<li><p>method=“simple”</p>
<ul>
<li>An intuitive solution: The distances between events and sampling points are replaced by network distances, and the formula of the kernel is adapted to calculate the density over a linear unit instead of an areal unit.</li>
</ul></li>
<li><p>method=“discontinuous”.</p>
<ul>
<li>Equally “divides” the mass density of an event at intersections of lixels.</li>
</ul></li>
<li><p>method=“continuous”</p>
<ul>
<li><p>If the “discontinuous” method is unbiased, it leads to a discontinuous kernel function which is a bit counter-intuitive.</p></li>
<li><p>This “continuous” method divides the mass of the density at intersection but adjusts the density before the intersection to make the function continuous.</p></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="visualizing-netkde" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-netkde">6.3.4 Visualizing NetKDE</h3>
<p>Before we can visualize the NetKDE values, we will use the code chunk below to insert the computed density values (i.e.&nbsp;densities) into centers and lixels objects as a density field.</p>
<p>Since the svy21 projection system is in metres, the computed density values are very small. Hence, we rescale the density values from the number of events per metre to number of events per kilometre using the code chunk below.</p>
<p>Then, we can prepare an interactive and high cartographic quality map visualization on openstreetmap of Singapore using the follow code:</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>